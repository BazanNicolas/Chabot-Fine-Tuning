{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "V9A2tnuoYt0y",
   "metadata": {
    "id": "V9A2tnuoYt0y"
   },
   "source": [
    "## Instalaci√≥n de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824151c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "824151c9",
    "outputId": "7f365b5f-9c47-4cf0-c418-41db1053459f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Install core libraries for text modeling and evaluation\n",
    "%pip -q install -U datasets accelerate transformers peft trl bitsandbytes sentencepiece einops\n",
    "%pip -q install -U matplotlib seaborn sentence_transformers\n",
    "\n",
    "# helpers\n",
    "%pip install wordcloud\n",
    "\n",
    "# Install Accelerate for efficient training and device management\n",
    "%pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc651c33",
   "metadata": {},
   "source": [
    "## Configuraci√≥n del entorno de ejecuci√≥n (GPU y Accelerate)\n",
    "\n",
    "Establecemos variables de entorno para controlar el uso de GPU y evitar problemas comunes al entrenar modelos en notebooks. En particular, se fuerza el uso de una √∫nica GPU y se desactiva el mixed precision de Accelerate para mejorar la estabilidad del entrenamiento en este entorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4d9ee-362b-4add-bf45-1006f4133b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use a single GPU to avoid DataParallel issues in notebooks.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # Or choose any GPU free\n",
    "\n",
    "# Force Accelerate to disable mixed precision (stability fix for this environment).\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uDGEbF-etgvz",
   "metadata": {
    "id": "uDGEbF-etgvz"
   },
   "source": [
    "## Importaci√≥n de librer√≠as\n",
    "\n",
    "Esta secci√≥n carga todas las dependencias necesarias para el procesamiento de texto, entrenamiento del modelo y utilidades auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab3ec4c",
   "metadata": {
    "id": "3ab3ec4c"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from datasets import DatasetDict, load_dataset\n",
    "from IPython.display import clear_output, display\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pzmVZes_t0LW",
   "metadata": {
    "id": "pzmVZes_t0LW"
   },
   "source": [
    "## Configuraci√≥n del dispositivo de ejecuci√≥n\n",
    "\n",
    "Establecemos el dispositivo de c√≥mputo a utilizar durante el entrenamiento y la inferencia. Utilizamos la GPU si est√° disponible, de lo contrario el c√≥digo se ejecuta en CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1773a86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1773a86a",
    "outputId": "a0eb0b4c-4079-4bb5-915b-1d5a2774f5e1"
   },
   "outputs": [],
   "source": [
    "# Detect compute device (informativo)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Dispositivo seleccionado: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPUs disponibles: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        name = torch.cuda.get_device_name(i)\n",
    "        cap = torch.cuda.get_device_capability(i)\n",
    "        print(f\"  GPU {i}: {name} ‚Äî Compute Capability: {cap}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NkRo-9meuHoy",
   "metadata": {
    "id": "NkRo-9meuHoy"
   },
   "source": [
    "## Par√°metros y filtros de datos irrelevantes\n",
    "\n",
    "En esta secci√≥n se definen patrones t√≠picos de WhatsApp que deben ser descartados durante la limpieza del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68a44de",
   "metadata": {
    "id": "a68a44de"
   },
   "outputs": [],
   "source": [
    "# Set of patterns considered irrelevant for training (WhatsApp system messages)\n",
    "irrelevant_data = {\n",
    "    # Spanish\n",
    "    \"eliminaste este mensaje\",\n",
    "    \"se elimin√≥ este mensaje\",\n",
    "    \"<multimedia omitido>\",\n",
    "    \"multimedia omitido\",\n",
    "    \"los mensajes y las llamadas est√°n cifrados de extremo a extremo\",\n",
    "\n",
    "    # English\n",
    "    \"you deleted this message\",\n",
    "    \"this message was deleted\",\n",
    "    \"<media omitted>\",\n",
    "    \"media omitted\",\n",
    "    \"messages and calls are end-to-end encrypted\",\n",
    "}\n",
    "\n",
    "def contains_irrelevant_data(message: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the message contains any irrelevant WhatsApp system string.\n",
    "    Assumes the input message has already been lowercased.\n",
    "    \"\"\"\n",
    "    return any(pattern in message for pattern in irrelevant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llnn1BwUxSWH",
   "metadata": {
    "id": "llnn1BwUxSWH"
   },
   "source": [
    "## Procesamiento del chat de WhatsApp\n",
    "\n",
    "Esta celda contiene todas las funciones relacionadas con la limpieza, parseo y estructuraci√≥n del chat de WhatsApp.\n",
    "No realiza acciones por s√≠ misma, solo define el procesamiento que luego ser√° utilizado por la interfaz interactiva.\n",
    "Contiene distintos separadores:\n",
    "\n",
    "* Tags con los que el modelo fue entrenado: <|system|>, <|user|>, <|assistant|>, <|end|>\n",
    "* Tags utilizados para los diferenciar interlocutores en los turnos [_Autor_], [OTRO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b28c9b",
   "metadata": {
    "id": "41b28c9b"
   },
   "outputs": [],
   "source": [
    "MSG_SEP = \"<|msg_sep|>\"  # Separator used inside a single turn\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Light text normalization for WhatsApp messages.\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-z√°√©√≠√≥√∫√±√º0-9,.;:¬°!¬ø?\\s']\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def parse_datetime(line: str):\n",
    "    \"\"\"Parse WhatsApp timestamp from a message line, if present.\"\"\"\n",
    "    match = re.match(r\"(\\d+/\\d+/\\d+[, ]\\s?\\d+:\\d+)\\s-\", line)\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    raw = match.group(1).replace(\",\", \"\")\n",
    "    for fmt in (\"%d/%m/%y %H:%M\", \"%d/%m/%Y %H:%M\"):\n",
    "        try:\n",
    "            return datetime.strptime(raw, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def group_consecutive_messages(messages):\n",
    "    \"\"\"Group consecutive messages from the same author when close in time.\"\"\"\n",
    "    grouped = []\n",
    "    for author, msg, ts in messages:\n",
    "        if (\n",
    "            grouped\n",
    "            and grouped[-1][0] == author\n",
    "            and ts is not None\n",
    "            and grouped[-1][2] is not None\n",
    "            and (ts - grouped[-1][2]) < timedelta(hours=1)\n",
    "        ):\n",
    "            prev_author, prev_msg, prev_ts = grouped[-1]\n",
    "            grouped[-1] = (author, f\"{prev_msg} {MSG_SEP} {msg}\", ts)\n",
    "        else:\n",
    "            grouped.append((author, msg, ts))\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def process_whatsapp_chat_phi3(\n",
    "    filepath: str,\n",
    "    target_author: str,\n",
    "    tokenizer,\n",
    "    k_history: int = 4,\n",
    "    time_gap: timedelta = timedelta(hours=3),\n",
    "    system_prompt: str = \"You are a helpful assistant.\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns a list of dicts with a single 'text' field formatted via Phi-3 chat template.\n",
    "    Each example trains the assistant to respond as `target_author`.\n",
    "    \"\"\"\n",
    "    print(\"Procesando chat (k-turns con roles) para Phi-3...\")\n",
    "\n",
    "    messages = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            ts = parse_datetime(line)\n",
    "            match = re.match(r\"\\d+/\\d+/\\d+[, ]\\s?\\d+:\\d+\\s-\\s([^:]+):\\s(.+)\", line)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            author = match.group(1).strip()\n",
    "            raw_msg = match.group(2)\n",
    "            msg = clean_text(raw_msg)\n",
    "\n",
    "            if msg and not contains_irrelevant_data(msg):\n",
    "                messages.append((author, msg, ts))\n",
    "\n",
    "    if not messages:\n",
    "        print(\"No se encontraron mensajes v√°lidos.\")\n",
    "        return []\n",
    "\n",
    "    messages = group_consecutive_messages(messages)\n",
    "    print(f\"Total de turnos agrupados: {len(messages)}\")\n",
    "\n",
    "    examples = []\n",
    "\n",
    "    for i in range(1, len(messages)):\n",
    "        author_i, msg_i, ts_i = messages[i]\n",
    "\n",
    "        if author_i != target_author:\n",
    "            continue\n",
    "\n",
    "        context = []\n",
    "        last_ts = ts_i\n",
    "\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            a_j, m_j, ts_j = messages[j]\n",
    "\n",
    "            if ts_j is not None and last_ts is not None and (last_ts - ts_j) > time_gap:\n",
    "                break\n",
    "\n",
    "            context.insert(0, (a_j, m_j))\n",
    "            if ts_j is not None:\n",
    "                last_ts = ts_j\n",
    "\n",
    "            if len(context) >= k_history:\n",
    "                break\n",
    "\n",
    "        if not context:\n",
    "            continue\n",
    "\n",
    "        def fmt_turn(author: str, msg: str) -> str:\n",
    "            speaker = f\"[{target_author}]\" if author == target_author else \"[OTRO]\"\n",
    "            return f\"{speaker} {msg}\"\n",
    "\n",
    "        context_str = \" \".join(fmt_turn(a, m) for (a, m) in context)\n",
    "\n",
    "        chat = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": context_str},\n",
    "            {\"role\": \"assistant\", \"content\": msg_i},\n",
    "        ]\n",
    "\n",
    "        text = tokenizer.apply_chat_template(\n",
    "            chat,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False,\n",
    "        )\n",
    "\n",
    "        examples.append({\"text\": text})\n",
    "\n",
    "    print(f\"Total de ejemplos generados: {len(examples)}\")\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eff7fe-bd18-48d9-b47b-860ddc6acb02",
   "metadata": {},
   "source": [
    "## Tokenizer del modelo\n",
    "\n",
    "Cargamos el tokenizer asociado al modelo base. Se utiliza durante el preprocesamiento para convertir el historial de conversaci√≥n al formato exacto requerido por el chat template del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61b38e-a520-428e-b497-c9adce27faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "# Ensure a valid padding token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "print(\"‚úÖ Tokenizer cargado\")\n",
    "print(\"pad_token:\", tokenizer.pad_token, \"| eos_token:\", tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QQ62_LUHxkq8",
   "metadata": {
    "id": "QQ62_LUHxkq8"
   },
   "source": [
    "## Procesamiento interactivo del chat\n",
    "\n",
    "Esta celda ofrece una interfaz interactiva para cargar el archivo del chat, ingresar el nombre del autor y ajustar par√°metros como el historial considerado y el tiempo m√°ximo entre mensajes. Permite procesar el chat sin modificar c√≥digo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3jEMtLjsvUt6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428,
     "referenced_widgets": [
      "1b89890b423249ddb03219ed985d6b62",
      "6afbafbc97a54acf9d380ae1249ca133",
      "000077e3c223477cb0974127a96bc659",
      "5a2fc8da6b934c85b941a5176456de43",
      "281c39c324384aa097590eac129a3aca",
      "1f588ccdb55e4858b356af6ba71c66b1",
      "c09e9e96550040789e4ee73f72a62412",
      "640f532bdc0d4fa598222c82e9cc034c",
      "716f457b8c774135a48d0b66b9f2240a",
      "63405775b29449c389d6e68f1baa7d58",
      "22f9603a839a47e3a9189db8e15c321c",
      "d048b13325434cdf828d5734027ee94e",
      "5d736683a7da43d8a0fcf6d2e568d042",
      "37066bd6b5dd4a96adf4dde0f00d0249",
      "54b5173fa8674eb9b1102bf9d459cad8",
      "64a1f1d0ac8c4a22bb0ecbd53b6fa308",
      "606382c47400446686a6ac8faca34364",
      "8d73ef5112a346a6ac9edfe7b91b8b1c",
      "386f1dc567e0401c89e32f2d2191ab35",
      "e2f56bcb29b046fc88286e440da594cb",
      "1514ad0ca9424e6e8cc2bbea339c6bf6",
      "95141b2d7da843b6bb6c63a2021acf7b"
     ]
    },
    "id": "3jEMtLjsvUt6",
    "outputId": "a644317b-7070-4cd6-ec79-0c055d96c4f2"
   },
   "outputs": [],
   "source": [
    "# File upload widget for WhatsApp chat export (.txt)\n",
    "chat_uploader = widgets.FileUpload(\n",
    "    accept=\".txt\",\n",
    "    multiple=False,\n",
    "    description=\"Subir chat (.txt)\"\n",
    ")\n",
    "\n",
    "# Text input for the target author (exactly as appears in the export)\n",
    "author_input = widgets.Text(\n",
    "    description=\"Autor:\",\n",
    "    placeholder=\"Nombre exactamente como figura en el chat\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "# System prompt template (author name is injected at runtime)\n",
    "SYSTEM_PROMPT_TEMPLATE = (\n",
    "    \"Sos un bot que responde mensajes de WhatsApp \"\n",
    "    \"imitando el estilo conversacional de {author}\"\n",
    ")\n",
    "\n",
    "# Slider for the number of history turns\n",
    "k_history_slider = widgets.IntSlider(\n",
    "    value=4,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"k_history:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Slider for the time gap (in hours) to cut sessions\n",
    "time_gap_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description=\"time_gap (h):\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Button to trigger processing\n",
    "process_button = widgets.Button(\n",
    "    description=\"Procesar chat\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "\n",
    "output_proc = widgets.Output()\n",
    "\n",
    "\n",
    "def on_process_clicked(_):\n",
    "    with output_proc:\n",
    "        clear_output()\n",
    "\n",
    "        # Basic validation\n",
    "        if len(chat_uploader.value) == 0:\n",
    "            print(\"Por favor, sube un archivo de chat en formato .txt.\")\n",
    "            return\n",
    "\n",
    "        target_author = author_input.value.strip()\n",
    "        if not target_author:\n",
    "            print(\"Por favor, ingresa el nombre del autor exactamente como aparece en el chat.\")\n",
    "            return\n",
    "\n",
    "        system_prompt = SYSTEM_PROMPT_TEMPLATE.format(author=target_author)\n",
    "\n",
    "        # Extract uploaded file content\n",
    "        upload_info = chat_uploader.value[0]\n",
    "        content = bytes(upload_info[\"content\"]).decode(\"utf-8-sig\", errors=\"replace\")\n",
    "\n",
    "        # Save to a temporary file for reuse\n",
    "        tmp_path = \"uploaded_chat.txt\"\n",
    "        with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        # Process chat and expose results as a global variable\n",
    "        global train_examples\n",
    "        train_examples = process_whatsapp_chat_phi3(\n",
    "            filepath=tmp_path,\n",
    "            target_author=target_author,\n",
    "            tokenizer=tokenizer,\n",
    "            k_history=k_history_slider.value,\n",
    "            time_gap=timedelta(hours=time_gap_slider.value),\n",
    "            system_prompt=system_prompt,\n",
    "        )\n",
    "\n",
    "        print(f\"Ejemplos generados: {len(train_examples)}\")\n",
    "        if train_examples:\n",
    "            print(\"\\nEjemplo de TEXT (Phi-3 chat template):\")\n",
    "            ex = train_examples[0][\"text\"]\n",
    "            print(ex[:800] + (\"...\" if len(ex) > 800 else \"\"))\n",
    "\n",
    "        print(\"\\nVariable disponible para las siguientes celdas: 'train_examples'.\")\n",
    "\n",
    "\n",
    "process_button.on_click(on_process_clicked)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HTML(\"<b>Procesamiento interactivo del chat de WhatsApp</b>\"),\n",
    "        chat_uploader,\n",
    "        author_input,\n",
    "        k_history_slider,\n",
    "        time_gap_slider,\n",
    "        process_button,\n",
    "        output_proc,\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KaSrQwXWzBjQ",
   "metadata": {
    "id": "KaSrQwXWzBjQ"
   },
   "source": [
    "## Creaci√≥n del dataset, limpieza y guardado\n",
    "\n",
    "Esta celda toma los ejemplos generados previamente, construye un DataFrame, aplica una limpieza b√°sica (elimina ejemplos triviales y enlaces) y guarda un archivo CSV con el dataset inicial. Adem√°s, muestra algunos ejemplos aleatorios para inspeccionar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aae1db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Safety check: train_examples must exist\n",
    "if \"train_examples\" not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"La variable 'train_examples' no existe. \"\n",
    "        \"Ejecuta primero el procesamiento interactivo del chat (Phi-3) para generar 'train_examples'.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def build_dataset_from_text(\n",
    "    examples,\n",
    "    min_words: int = 12,\n",
    "    filter_links: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build a DataFrame from Phi-3 formatted samples (each sample is {\"text\": ...}).\n",
    "    The function drops invalid rows, filters very short samples, and optionally removes URLs.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(examples)\n",
    "    if \"text\" not in df.columns:\n",
    "        raise ValueError(\"Cada ejemplo debe tener la clave 'text'.\")\n",
    "\n",
    "    df = df.dropna(subset=[\"text\"]).reset_index(drop=True)\n",
    "    df = df[df[\"text\"].str.split().str.len() >= min_words].reset_index(drop=True)\n",
    "\n",
    "    if filter_links:\n",
    "        df = df[~df[\"text\"].str.contains(r\"http|www|\\.com\", regex=True)].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Default configuration\n",
    "min_words_default = 12\n",
    "filter_links_default = True\n",
    "output_path_default = \"train_data_phi3_text.csv\"\n",
    "\n",
    "data = build_dataset_from_text(\n",
    "    train_examples,\n",
    "    min_words=min_words_default,\n",
    "    filter_links=filter_links_default,\n",
    ")\n",
    "\n",
    "data.to_csv(output_path_default, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "print(f\"Dataset inicial guardado ‚Üí {len(data)} ejemplos.\")\n",
    "print(\"\\nVista aleatoria de algunos ejemplos:\\n\")\n",
    "\n",
    "for _ in range(min(5, len(data))):\n",
    "    s = data.sample(1).iloc[0]\n",
    "    text = s[\"text\"]\n",
    "    print(f\"TEXT (Phi-3):\\n{text[:900]}{'...' if len(text) > 900 else ''}\\n{'-'*70}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0MLkir1uzpxw",
   "metadata": {
    "id": "0MLkir1uzpxw"
   },
   "source": [
    "## Filtrado sem√°ntico global\n",
    "\n",
    "Esta celda aplica un filtrado sem√°ntico basado en embeddings para conservar √∫nicamente ejemplos con alta coherencia sem√°ntica entre el mensaje del usuario y la respuesta del asistente.\n",
    "Se calcula la similitud coseno, se filtran ejemplos ruidosos y se guarda el dataset final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0115728a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539,
     "referenced_widgets": [
      "5ff427dd866d407a871c2ee09717fb71",
      "081eac8ac59942d78338412589a88bc5",
      "b740b650766d4f37a726e446d315f6df",
      "f0918d6914844df8be487183b2406baa",
      "97c87949d2bd49e88ccfa1f4dd9326cf",
      "0523b6f5933b4dd5922766a1fcba0d78",
      "c6435a321a1e4875bf63952447887b77",
      "3df323df78aa4b92a202dadfc96ce075",
      "55a5d08862dd446595c68ed061dcd860",
      "e254882eeb8443658a6f037d654f0032",
      "5dedbcbc4bdc458bb17dcac1063ed017",
      "c3f3f23759714a02b0c4a11ffcef09d6",
      "f306d239ed9047ddbae48e830ff0e6c7",
      "4d78106f1c194d55983b58c1e44383b5",
      "b3cd5c2b87d745d489eaa52d8d9e354e",
      "d71a7989630f41c6811674058b2a1a5b",
      "0b0fbe7a20ca465b872fd12ba3e8a043",
      "b3880be52dd04da1830ba8537b92efe7",
      "44de7c02ff9f4db78d3a83392220e4b1",
      "6f39d1805738418b929132e9d57d66b3",
      "14b03e931fdf4a408ff52fb0286bd58f",
      "d91cc7a0aaf743b4aeff8be2958d7464"
     ]
    },
    "id": "0115728a",
    "outputId": "ea133d03-fb6f-4c28-bbb9-2f40b7235a64"
   },
   "outputs": [],
   "source": [
    "# Load the sentence transformer model once\n",
    "if \"model_emb\" not in globals():\n",
    "    model_emb = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "\n",
    "def extract_user_and_assistant(phi3_text: str):\n",
    "    \"\"\"\n",
    "    Extracts the first <|user|> ... <|end|> and <|assistant|> ... <|end|> blocks\n",
    "    from a Phi-3 formatted text.\n",
    "    Returns (user_text, assistant_text) or (None, None) if parsing fails.\n",
    "    \"\"\"\n",
    "    if not isinstance(phi3_text, str):\n",
    "        return None, None\n",
    "\n",
    "    user_match = re.search(r\"<\\|user\\|>\\s*(.*?)\\s*<\\|end\\|>\", phi3_text, flags=re.DOTALL)\n",
    "    asst_match = re.search(r\"<\\|assistant\\|>\\s*(.*?)\\s*<\\|end\\|>\", phi3_text, flags=re.DOTALL)\n",
    "\n",
    "    user_text = user_match.group(1).strip() if user_match else None\n",
    "    assistant_text = asst_match.group(1).strip() if asst_match else None\n",
    "    return user_text, assistant_text\n",
    "\n",
    "\n",
    "# Build user / assistant columns from Phi-3 text\n",
    "ua = data[\"text\"].apply(extract_user_and_assistant)\n",
    "data[\"user_text\"] = ua.apply(lambda x: x[0])\n",
    "data[\"assistant_text\"] = ua.apply(lambda x: x[1])\n",
    "\n",
    "# Drop rows that could not be parsed correctly\n",
    "data = data.dropna(subset=[\"user_text\", \"assistant_text\"]).reset_index(drop=True)\n",
    "\n",
    "# Encode user and assistant messages\n",
    "emb_users = model_emb.encode(\n",
    "    data[\"user_text\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "emb_assts = model_emb.encode(\n",
    "    data[\"assistant_text\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    ")\n",
    "\n",
    "# Compute cosine similarity for each pair\n",
    "similarities = util.cos_sim(emb_users, emb_assts).diagonal().cpu().numpy()\n",
    "data[\"similarity\"] = similarities\n",
    "\n",
    "print(f\"Media de similitud: {data['similarity'].mean():.3f}\")\n",
    "\n",
    "# Filtering configuration\n",
    "SIM_THRESHOLD = 0.30\n",
    "MAX_USER_LEN = 1200\n",
    "MAX_ASSISTANT_LEN = 800\n",
    "\n",
    "filtered = data[\n",
    "    (data[\"similarity\"] > SIM_THRESHOLD)\n",
    "    & (data[\"user_text\"].str.len() < MAX_USER_LEN)\n",
    "    & (data[\"assistant_text\"].str.len() < MAX_ASSISTANT_LEN)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# Save final training dataset (Phi-3 text only)\n",
    "output_filtered_path = \"filtered_train_phi3_text.csv\"\n",
    "filtered[[\"text\"]].to_csv(output_filtered_path, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Optional debug dataset for inspection\n",
    "output_debug_path = \"filtered_train_phi3_debug.csv\"\n",
    "filtered[[\"user_text\", \"assistant_text\", \"similarity\"]].to_csv(\n",
    "    output_debug_path, index=False, quoting=csv.QUOTE_ALL\n",
    ")\n",
    "\n",
    "print(f\"Dataset final (solo text) guardado en '{output_filtered_path}'.\")\n",
    "print(f\"Dataset debug guardado en '{output_debug_path}'.\")\n",
    "print(f\"Total de ejemplos √∫tiles: {len(filtered)} (de {len(data)}).\")\n",
    "\n",
    "print(\"\\nVista r√°pida de algunos ejemplos filtrados:\\n\")\n",
    "for _ in range(min(3, len(filtered))):\n",
    "    s = filtered.sample(1).iloc[0]\n",
    "    print(\n",
    "        f\"USER:\\n{s['user_text']}\\n\"\n",
    "        f\"‚Üí ASSISTANT:\\n{s['assistant_text']}\\n\"\n",
    "        f\"Similarity: {s['similarity']:.3f}\\n\"\n",
    "        + \"-\" * 70\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vd_KTL_E3pSU",
   "metadata": {
    "id": "vd_KTL_E3pSU"
   },
   "source": [
    "## Preparaci√≥n del dataset para entrenamiento\n",
    "\n",
    "Esta celda carga el dataset filtrado en formato Phi-3 (text), realiza una limpieza m√≠nima, lo convierte a datasets.Dataset y lo divide en entrenamiento y validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852a42e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets": [
      "7261dd8dcb8642a5af09d438949f92eb",
      "6fcadb3d803a4242867e482192a54a8d",
      "f34d3b82ee69493d875fb0e6e5c4e279",
      "974cdc2c42ed478eb7fe57b297ea5d8d",
      "1ee3cdcc9c5f44aca8102fcac055fa7b",
      "f3385ca7ad084b76b54bd792c5c12ecc",
      "b37c77039daa4165ace0be1507c4124c",
      "eda887369c4d450f855ebecc8bfb3f4b",
      "a8111075fbd045b7a04864291fb79ef3",
      "757b8d1a630d472ebded8cc6d0ae2c7d",
      "38a1ffb2e99047f18f80780e21da2e09",
      "a7d44eeadec440b885db0b3266aff313",
      "7afa75f5ab2c4797b3bf7040d420a9f1",
      "4440cab6284145629c7bb21906b0dd08",
      "23c66bbba40e433f9487149dde5ef7ad",
      "c621cce4af43498c86a9db93fa37d9d2",
      "ee5a23335ed2409896ba872cf65a8de2",
      "0d9b7e0264f04847847001bd062e75dc",
      "731ab9c47cad4cb0b2376f97f270d3c7",
      "166cae34ef4742e68ee37d6d9b55204d",
      "b31b99f3917e4c59861357632713da86",
      "1244f08ba56846b392169c6b39d4ecc9",
      "4ccc4bb50c9d4a93a95f3db1cdc4363c",
      "eaf0a883b0c24044ad7444452a57a5df",
      "5baf19d9a1c34043aa6a7b9bac84aa24",
      "d1086cde5e554ce48cdad8a7994cec43",
      "50a3c9e3797b4f529f107aa67bd59797",
      "7089428aff0b4bafb56fde74ecd2c3e5",
      "eabf5e94e97a4cd5aeb7993498bdb3b2",
      "de0fb81662ce40e58b8dd095e5e041eb",
      "d4297894b3bd43c4af3bdbcd491ea44f",
      "c6b5b1bb6987432fa77a40789433950e",
      "007644d9a9654065803eb013474685b7"
     ]
    },
    "id": "2852a42e",
    "outputId": "a2cd3b30-4c8d-4e7b-8046-5936e0728653"
   },
   "outputs": [],
   "source": [
    "# Load and minimally clean the dataset (Phi-3 format: 'text' column)\n",
    "data = pd.read_csv(\"filtered_train_phi3_text.csv\")\n",
    "data = data.dropna(subset=[\"text\"])\n",
    "data = data[data[\"text\"].str.strip() != \"\"].reset_index(drop=True)\n",
    "data.to_csv(\"filtered_train_phi3_text.csv\", index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Load into HuggingFace datasets\n",
    "dataset = load_dataset(\"csv\", data_files=\"filtered_train_phi3_text.csv\")\n",
    "\n",
    "# Train/validation split\n",
    "train_test = dataset[\"train\"].train_test_split(test_size=0.2, seed=42)\n",
    "datasets = DatasetDict(\n",
    "    {\"train\": train_test[\"train\"], \"validation\": train_test[\"test\"]}\n",
    ")\n",
    "\n",
    "print(datasets)\n",
    "print(\"Ejemplo:\")\n",
    "print(datasets[\"train\"][0][\"text\"][:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2907a4-d26d-45a4-a290-a9c26cd4119e",
   "metadata": {},
   "source": [
    "## Carga del modelo base Phi-3 con QLoRA\n",
    "\n",
    "Esta celda carga el modelo base Phi-3 Mini Instruct utilizando cuantizaci√≥n en 4 bits (QLoRA).\n",
    "Se inicializa el tokenizer, se configura el padding y se prepara el modelo para fine-tuning eficiente mediante adapters LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583072c-88e8-49f4-8a17-1195952754ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QLoRA configuration (4-bit quantization)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Base model loaded in 4-bit mode\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,  # Disabled for training with gradient checkpointing\n",
    ")\n",
    "\n",
    "# Prepare model for k-bit (QLoRA) training\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "print(\"‚úÖ Modelo base cargados en 4-bit (listos para aplicar LoRA).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b0855-bdfa-4edd-9b92-b049e632ff21",
   "metadata": {},
   "source": [
    "## Aplicaci√≥n de adapters LoRA al modelo base\n",
    "\n",
    "Esta celda configura y aplica LoRA (Low-Rank Adaptation) sobre el modelo base Phi-3 previamente cargado.\n",
    "Se definen los hiperpar√°metros de LoRA y los m√≥dulos objetivo que ser√°n ajustados durante el fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e6f7c-d43f-4c54-a959-a54f71370a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        # Common projection layers used in transformer architectures\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Attach LoRA adapters to the base model\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# Display number of trainable vs frozen parameters\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "print(\"‚úÖ LoRA aplicado (modelo listo para SFTTrainer).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b5df97-5e2b-417b-b5dc-ee3a07c57ae2",
   "metadata": {},
   "source": [
    "### An√°lisis estad√≠stico y calidad del dataset final (Phi-3)\n",
    "\n",
    "Este bloque analiza exclusivamente el dataset conversacional final utilizado para el entrenamiento del modelo Phi-3 Instruct.\n",
    "El objetivo es evaluar la calidad del conjunto de datos que efectivamente se usa durante el fine-tuning supervisado, verificando su tama√±o, diversidad ling√º√≠stica y adecuaci√≥n al contexto del modelo.\n",
    "\n",
    "En particular, se reportan las siguientes m√©tricas:\n",
    "\n",
    "* Samples: cantidad total de ejemplos de entrenamiento presentes en el dataset final.\n",
    "\n",
    "* Exact duplicates: n√∫mero de ejemplos id√©nticos detectados. Un valor bajo indica que no hay sobre-representaci√≥n artificial de conversaciones repetidas.\n",
    "\n",
    "* Chars avg: longitud promedio de los ejemplos medida en caracteres. Proporciona una noci√≥n general del tama√±o del texto sin depender del tokenizer.\n",
    "\n",
    "* Words avg: cantidad promedio de palabras por ejemplo, utilizada como medida ling√º√≠stica intuitiva de la longitud del contenido.\n",
    "\n",
    "* Words p95: percentil 95 de la longitud en palabras. Indica que el 95% de los ejemplos tiene una longitud menor o igual a este valor y permite identificar conversaciones largas.\n",
    "\n",
    "* Unique words: cantidad total de palabras distintas presentes en el dataset final, lo que refleja el tama√±o efectivo del vocabulario.\n",
    "\n",
    "* Vocab richness (%): proporci√≥n entre palabras √∫nicas y el total de palabras. Valores relativamente bajos son esperables en chats personales y reflejan consistencia de estilo y repetici√≥n de expresiones.\n",
    "\n",
    "* Tokens avg: cantidad promedio de tokens por ejemplo seg√∫n el tokenizer de Phi-3, que representa lo que realmente procesa el modelo durante el entrenamiento.\n",
    "\n",
    "* Tokens p95: percentil 95 de la longitud en tokens. Es una m√©trica clave para estimar el uso del contexto y evitar truncamiento durante el fine-tuning.\n",
    "\n",
    "Adem√°s, se incluye un ranking de las palabras m√°s frecuentes del dataset final, presentado en dos vistas complementarias:\n",
    "\n",
    "* Con muletillas: frecuencia cruda de palabras, √∫til para detectar expresiones repetidas, muletillas y patrones conversacionales caracter√≠sticos del autor.\n",
    "\n",
    "* Sin muletillas: frecuencia filtrada eliminando stopwords comunes y ruido residual del template, √∫til para identificar temas, contenidos y vocabulario informativo dominante.\n",
    "\n",
    "Finalmente, se muestra una nube de palabras construida a partir del vocabulario informativo del dataset final, donde las palabras m√°s frecuentes aparecen visualmente destacadas. Esta visualizaci√≥n permite caracterizar de forma r√°pida el estilo y los temas predominantes que el modelo aprender√° durante el entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c551277b-536e-4317-a758-5bb94b4cff91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    WORDCLOUD_AVAILABLE = True\n",
    "except Exception:\n",
    "    WORDCLOUD_AVAILABLE = False\n",
    "\n",
    "# Safety check: final dataset only\n",
    "assert \"filtered\" in globals() and isinstance(filtered, pd.DataFrame) and \"text\" in filtered.columns, \\\n",
    "    \"‚ùå 'filtered' no existe o no tiene columna 'text' (dataset final de Phi-3)\"\n",
    "\n",
    "texts = filtered[\"text\"].astype(str).tolist()\n",
    "texts = [t for t in texts if t.strip()]\n",
    "\n",
    "# Regex & helpers\n",
    "WORD_RE = re.compile(r\"[a-z√°√©√≠√≥√∫√±√º0-9']+\")\n",
    "\n",
    "# Phi-3 template tags\n",
    "TAG_RE_GENERIC = re.compile(r\"<\\|.*?\\|>\")\n",
    "\n",
    "# Remove full system block (<|system|> ... <|end|>)\n",
    "SYSTEM_BLOCK_PHI3_RE = re.compile(\n",
    "    r\"<\\|system\\|>\\s*.*?\\s*<\\|end\\|>\",\n",
    "    re.DOTALL | re.IGNORECASE\n",
    ")\n",
    "\n",
    "# Dynamic author filtering\n",
    "AUTHOR_STOP_WORDS = set()\n",
    "if \"author_input\" in globals() and author_input.value.strip():\n",
    "    AUTHOR_STOP_WORDS = {\n",
    "        w for w in re.findall(r\"[a-z√°√©√≠√≥√∫√±√º]+\", author_input.value.strip().lower())\n",
    "        if len(w) >= 2\n",
    "    }\n",
    "\n",
    "# Stopwords\n",
    "STOP_WORDS_EXTRA = {\n",
    "    \"user\", \"assistant\", \"system\",\n",
    "    \"metadata\", \"knowledge\", \"cutoff\", \"date\", \"today\",\n",
    "    \"reasoning\", \"mode\", \"custom\", \"instructions\",\n",
    "    \"im_start\", \"im_end\", \"end\", \"msg_sep\",\n",
    "    \"think\", \"no_think\"\n",
    "}.union(AUTHOR_STOP_WORDS)\n",
    "\n",
    "SPANISH_STOPWORDS = {\n",
    "    \"el\",\"la\",\"los\",\"las\",\"un\",\"una\",\"unos\",\"unas\",\n",
    "    \"yo\",\"me\",\"te\",\"se\",\"lo\",\"le\",\"nos\",\"les\",\n",
    "    \"de\",\"que\",\"y\",\"o\",\"pero\",\"si\",\"no\",\"es\",\"en\",\"con\",\"por\",\"para\",\n",
    "    \"ya\",\"bien\",\"eh\",\"ah\",\"oh\",\"xd\",\"jaja\",\"jajaja\"\n",
    "}\n",
    "\n",
    "# Normalization\n",
    "def normalize_for_stats(text: str) -> str:\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Remove full system prompt\n",
    "    text = SYSTEM_BLOCK_PHI3_RE.sub(\" \", text)\n",
    "\n",
    "    # Remove remaining tags\n",
    "    text = TAG_RE_GENERIC.sub(\" \", text)\n",
    "\n",
    "    # Normalize\n",
    "    text = text.replace(\"\\n\", \" \").lower()\n",
    "    text = re.sub(r\"\\d+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def extract_words(text: str):\n",
    "    words = WORD_RE.findall(normalize_for_stats(text))\n",
    "    return [w for w in words if w not in STOP_WORDS_EXTRA and len(w) >= 2]\n",
    "\n",
    "def extract_informative_words(text: str):\n",
    "    return [w for w in extract_words(text) if w not in SPANISH_STOPWORDS]\n",
    "\n",
    "# Dataset statistics\n",
    "\n",
    "char_lengths = [len(t) for t in texts]\n",
    "word_lengths = [len(extract_words(t)) for t in texts]\n",
    "\n",
    "vocab_raw = Counter()\n",
    "for t in texts:\n",
    "    vocab_raw.update(extract_words(t))\n",
    "\n",
    "stats = {\n",
    "    \"samples\": len(texts),\n",
    "    \"exact_duplicates\": int(pd.Series(texts).duplicated().sum()),\n",
    "    \"chars_avg\": float(sum(char_lengths) / max(1, len(texts))),\n",
    "    \"words_avg\": float(sum(word_lengths) / max(1, len(texts))),\n",
    "    \"words_p95\": float(pd.Series(word_lengths).quantile(0.95)),\n",
    "    \"unique_words\": int(len(vocab_raw)),\n",
    "    \"vocab_richness_pct\": 100.0 * len(vocab_raw) / max(1, sum(vocab_raw.values())),\n",
    "}\n",
    "\n",
    "# Token stats (if tokenizer exists)\n",
    "if \"tokenizer\" in globals() and tokenizer is not None:\n",
    "    try:\n",
    "        token_lengths = [\n",
    "            len(tokenizer(t, add_special_tokens=False).input_ids)\n",
    "            for t in texts\n",
    "        ]\n",
    "        stats.update({\n",
    "            \"tokens_avg\": float(sum(token_lengths) / max(1, len(token_lengths))),\n",
    "            \"tokens_p95\": float(pd.Series(token_lengths).quantile(0.95)),\n",
    "        })\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "summary_df = pd.DataFrame([stats])\n",
    "\n",
    "print(\"\\nüìä Resumen estad√≠stico ‚Äî Dataset final (Phi-3)\")\n",
    "display(summary_df)\n",
    "\n",
    "\n",
    "# Top words: with / without stopwords\n",
    "TOP_K = 20\n",
    "print(f\"\\nüîù Top {TOP_K} palabras (dataset final)\")\n",
    "\n",
    "top_raw = pd.DataFrame(\n",
    "    vocab_raw.most_common(TOP_K),\n",
    "    columns=[\"palabra\", \"frecuencia\"]\n",
    ")\n",
    "\n",
    "vocab_info = Counter()\n",
    "for t in texts:\n",
    "    vocab_info.update(extract_informative_words(t))\n",
    "\n",
    "top_info = pd.DataFrame(\n",
    "    vocab_info.most_common(TOP_K),\n",
    "    columns=[\"palabra\", \"frecuencia\"]\n",
    ")\n",
    "\n",
    "max_len = max(len(top_raw), len(top_info))\n",
    "top_raw = top_raw.reindex(range(max_len))\n",
    "top_info = top_info.reindex(range(max_len))\n",
    "\n",
    "spacer = pd.DataFrame({\"\": [\"\"] * max_len})\n",
    "spacer.columns = pd.MultiIndex.from_product([[\"\"], [\"\"]])\n",
    "\n",
    "top_raw.columns = pd.MultiIndex.from_product([[\"Con muletillas\"], top_raw.columns])\n",
    "top_info.columns = pd.MultiIndex.from_product([[\"Sin muletillas\"], top_info.columns])\n",
    "\n",
    "display(pd.concat([top_raw, spacer, top_info], axis=1))\n",
    "\n",
    "# Word cloud (informative words)\n",
    "if WORDCLOUD_AVAILABLE:\n",
    "    print(\"\\nüñºÔ∏è Nube de palabras ‚Äî Dataset final (sin stopwords)\")\n",
    "    wc_vocab = Counter()\n",
    "    for t in texts:\n",
    "        wc_vocab.update(extract_informative_words(t))\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        background_color=\"white\",\n",
    "        max_words=120,\n",
    "        collocations=False\n",
    "    ).generate_from_frequencies(dict(wc_vocab))\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n‚ÑπÔ∏è WordCloud no disponible (pip install wordcloud)\")\n",
    "\n",
    "# Final info\n",
    "print(\"‚Ä¢ Modelo objetivo: Phi-3 Instruct\")\n",
    "print(\"‚Ä¢ Dataset analizado: dataset final de entrenamiento (columna 'text')\")\n",
    "print(\"‚Ä¢ Nota: el bloque <|system|>‚Ä¶<|end|> se elimina SOLO para estad√≠sticas\")\n",
    "print(f\"‚Ä¢ Total de ejemplos: {len(texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02XSq4N_4p4m",
   "metadata": {
    "id": "02XSq4N_4p4m"
   },
   "source": [
    "## Argumentos de entrenamiento\n",
    "\n",
    "Define los hiperpar√°metros principales de entrenamiento para el fine-tuning del modelo (n√∫mero de √©pocas, batch size, tasa de aprendizaje, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd80ab5",
   "metadata": {
    "id": "edd80ab5"
   },
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir = f\"./models/{author_input.value.strip()}_whatsapp_phi3\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "\n",
    "    learning_rate=1e-4,  # Typical LoRA/QLoRA learning rate range\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    eval_strategy=\"no\",\n",
    "    report_to=\"none\",\n",
    "\n",
    "    bf16=True,\n",
    "    fp16=False,\n",
    "    gradient_checkpointing=True,\n",
    "\n",
    "    dataset_text_field=\"text\",\n",
    "    max_length=2048,\n",
    "    packing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lXmpmSWK45fj",
   "metadata": {
    "id": "lXmpmSWK45fj"
   },
   "source": [
    "## Configuraci√≥n del Trainer\n",
    "\n",
    "Configura el objeto que orquesta el entrenamiento con TRL (SFTTrainer), conectando el modelo, los datasets y los argumentos. La tokenizaci√≥n y el armado de labels se gestionan internamente a partir del campo text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f808f39",
   "metadata": {
    "id": "6f808f39"
   },
   "outputs": [],
   "source": [
    "trainer = None\n",
    "\n",
    "try:\n",
    "    # Newer TRL versions\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets[\"train\"],\n",
    "        eval_dataset=datasets[\"validation\"],\n",
    "        processing_class=tokenizer,\n",
    "    )\n",
    "    print(\"‚úÖ SFTTrainer creado usando processing_class=tokenizer\")\n",
    "except TypeError:\n",
    "    # Older TRL versions\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=datasets[\"train\"],\n",
    "        eval_dataset=datasets[\"validation\"],\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    print(\"‚úÖ SFTTrainer creado usando tokenizer=tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IOP5FaXQ5e7N",
   "metadata": {
    "id": "IOP5FaXQ5e7N"
   },
   "source": [
    "## Entrenamiento y guardado del modelo\n",
    "\n",
    "Esta celda entrena el modelo y guarda los adapters LoRA y el tokenizer en un directorio cuyo nombre se genera autom√°ticamente en funci√≥n del autor seleccionado en la etapa de procesamiento interactivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17101b70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "17101b70",
    "outputId": "f9f5a23a-3a56-46bb-e487-5e44c20475cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build dynamic save directory from author_input\n",
    "if \"author_input\" in globals():\n",
    "    author_name = author_input.value.strip()\n",
    "    safe_author = re.sub(r\"[^A-Za-z0-9_-]\", \"_\", author_name)\n",
    "    save_dir = f\"./bot_{safe_author}\" if safe_author else \"./bot_model\"\n",
    "else:\n",
    "    save_dir = \"./bot_model\"\n",
    "\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Guardando adapters LoRA + tokenizer en: {save_dir}\")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "finally:\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Save LoRA adapters + tokenizer (QLoRA workflow)\n",
    "trainer.model.save_pretrained(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"‚úÖ Adapters LoRA + tokenizer guardados en: {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R39Q3MBr6Z5E",
   "metadata": {
    "id": "R39Q3MBr6Z5E"
   },
   "source": [
    "## Comparador de respuestas entre modelos\n",
    "\n",
    "Esta celda carga el modelo base y el modelo fine-tuneado, y define un comparador para generar respuestas con ambos a partir de un mismo prompt. De esta forma se puede inspeccionar cualitativamente el efecto del fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681c893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7681c893",
    "outputId": "25746386-54f0-42b5-ac98-132721df9585",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ensure save_dir exists (from training step)\n",
    "if \"save_dir\" not in globals():\n",
    "    save_dir = \"./bot_model\"\n",
    "\n",
    "# Ensure a system prompt exists\n",
    "if \"SYSTEM_PROMPT\" not in globals() or not isinstance(SYSTEM_PROMPT, str) or not SYSTEM_PROMPT.strip():\n",
    "    SYSTEM_PROMPT = f\"Sos un bot que responde mensajes de WhatsApp imitando el estilo conversacional de ${author_input.value.strip()}\"\n",
    "\n",
    "# Load base Phi-3 model (4-bit)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    ")\n",
    "base_model.eval()\n",
    "\n",
    "# Load a separate base model instance for the LoRA-augmented model (clean comparison)\n",
    "fine_base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    use_cache=False,\n",
    ")\n",
    "fine_model = PeftModel.from_pretrained(fine_base_model, save_dir)\n",
    "fine_model.eval()\n",
    "\n",
    "print(f\"‚úÖ Base model: {MODEL_ID}\")\n",
    "print(f\"‚úÖ Fine model (LoRA adapters): {save_dir}\")\n",
    "\n",
    "\n",
    "def generate_response_phi3(\n",
    "    user_prompt: str,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    system_prompt: str = SYSTEM_PROMPT,\n",
    "    max_new_tokens: int = 80,\n",
    "    temperature: float = 0.8,\n",
    "    top_p: float = 0.92,\n",
    ") -> str:\n",
    "    \"\"\"Generates a single assistant response using Phi-3 chat template.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt.strip()},\n",
    "    ]\n",
    "\n",
    "    prompt_text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Move tensors to the first parameter device when possible (works with device_map=\"auto\")\n",
    "    try:\n",
    "        param_device = next(model.parameters()).device\n",
    "        inputs = {k: v.to(param_device) for k, v in inputs.items()}\n",
    "    except StopIteration:\n",
    "        pass\n",
    "\n",
    "    # Disable KV cache to avoid DynamicCache/seen_tokens incompatibilities in some environments\n",
    "    if hasattr(model, \"config\"):\n",
    "        model.config.use_cache = False\n",
    "    if hasattr(model, \"generation_config\"):\n",
    "        model.generation_config.use_cache = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            repetition_penalty=1.15,\n",
    "            no_repeat_ngram_size=3,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            use_cache=False,\n",
    "        )\n",
    "\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # Keep only the assistant segment\n",
    "    if \"<|assistant|>\" in decoded:\n",
    "        decoded = decoded.split(\"<|assistant|>\")[-1]\n",
    "    if \"<|end|>\" in decoded:\n",
    "        decoded = decoded.split(\"<|end|>\")[0]\n",
    "\n",
    "    return re.sub(r\"\\s+\", \" \", decoded).strip() or \"(no generated response)\"\n",
    "\n",
    "\n",
    "def compare_models(user_prompt: str):\n",
    "    print(f\"\\nPrompt:\\n{user_prompt}\")\n",
    "\n",
    "    base_resp = generate_response_phi3(user_prompt, base_model, tokenizer, system_prompt=SYSTEM_PROMPT)\n",
    "    fine_resp = generate_response_phi3(user_prompt, fine_model, tokenizer, system_prompt=SYSTEM_PROMPT)\n",
    "\n",
    "    print(\"\\n----------------------------------\")\n",
    "    print(\"Base model:\\n\", base_resp)\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Fine-tuned (LoRA):\\n\", fine_resp)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "\n",
    "def extract_user_from_text(phi3_text: str):\n",
    "    \"\"\"Extracts the user message from a Phi-3 formatted sample.\"\"\"\n",
    "    m = re.search(r\"<\\|user\\|>\\s*(.*?)\\s*<\\|end\\|>\", phi3_text, flags=re.DOTALL)\n",
    "    return m.group(1).strip() if m else None\n",
    "\n",
    "\n",
    "val_user_prompts = []\n",
    "for ex in datasets[\"validation\"]:\n",
    "    u = extract_user_from_text(ex[\"text\"])\n",
    "    if u:\n",
    "        val_user_prompts.append(u)\n",
    "\n",
    "sample_prompts = random.sample(val_user_prompts, min(5, len(val_user_prompts)))\n",
    "\n",
    "print(\"\\n=== Comparaci√≥n de modelos usando muestras de validaci√≥n ===\")\n",
    "for p in sample_prompts:\n",
    "    compare_models(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qMcU7Rw77hYC",
   "metadata": {
    "id": "qMcU7Rw77hYC"
   },
   "source": [
    "## Evaluaci√≥n cuantitativa y reporte final\n",
    "\n",
    "Esta celda eval√∫a cuantitativamente el modelo base y el modelo fine-tuneado sobre el conjunto de validaci√≥n. Se calcula la p√©rdida media de cross-entropy y la perplexity aproximada, y se reporta la mejora relativa del modelo fine-tuneado. Finalmente, se muestra una comparaci√≥n gr√°fica sencilla entre ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044a4d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "0044a4d8",
    "outputId": "03401036-f937-40fb-c39e-e0988f8bfccd"
   },
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "def evaluate_model_phi3(\n",
    "    model,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    max_examples: int = 200,\n",
    "    max_length: int = 2048,\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluates a causal LM on a dataset with a 'text' column (Phi-3 chat template).\n",
    "    Computes mean cross-entropy loss and perplexity (exp(loss)) over the selected subset.\n",
    "\n",
    "    Note: This is a global metric over the full sample (system + user + assistant).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, example in enumerate(tqdm(dataset, desc=\"Evaluando...\")):\n",
    "            if i >= max_examples:\n",
    "                break\n",
    "\n",
    "            text = example.get(\"text\", None)\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                continue\n",
    "\n",
    "            enc = tokenizer(\n",
    "                text,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "            )\n",
    "\n",
    "            # Move tensors to a valid parameter device (works with device_map=\"auto\")\n",
    "            try:\n",
    "                param_device = next(model.parameters()).device\n",
    "                enc = {k: v.to(param_device) for k, v in enc.items()}\n",
    "            except StopIteration:\n",
    "                pass\n",
    "\n",
    "            input_ids = enc[\"input_ids\"]\n",
    "            outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "            losses.append(float(outputs.loss))\n",
    "\n",
    "    n = len(losses)\n",
    "    avg_loss = sum(losses) / max(1, n)\n",
    "\n",
    "    try:\n",
    "        perp = math.exp(avg_loss)\n",
    "    except OverflowError:\n",
    "        perp = float(\"inf\")\n",
    "\n",
    "    return {\"cross_entropy\": avg_loss, \"perplexity\": perp, \"n\": n}\n",
    "\n",
    "\n",
    "metrics_base = evaluate_model_phi3(\n",
    "    base_model, datasets[\"validation\"], tokenizer, max_examples=200, max_length=2048\n",
    ")\n",
    "metrics_fine = evaluate_model_phi3(\n",
    "    fine_model, datasets[\"validation\"], tokenizer, max_examples=200, max_length=2048\n",
    ")\n",
    "\n",
    "print(\"\\nResultados de evaluaci√≥n:\")\n",
    "print(\n",
    "    f\"Base model  ‚Üí CE: {metrics_base['cross_entropy']:.3f} | \"\n",
    "    f\"PPL: {metrics_base['perplexity']:.2f} | n={metrics_base['n']}\"\n",
    ")\n",
    "print(\n",
    "    f\"Fine-tuned  ‚Üí CE: {metrics_fine['cross_entropy']:.3f} | \"\n",
    "    f\"PPL: {metrics_fine['perplexity']:.2f} | n={metrics_fine['n']}\"\n",
    ")\n",
    "\n",
    "if metrics_base[\"perplexity\"] != float(\"inf\") and metrics_base[\"perplexity\"] > 0:\n",
    "    improvement = (\n",
    "        (metrics_base[\"perplexity\"] - metrics_fine[\"perplexity\"])\n",
    "        / metrics_base[\"perplexity\"]\n",
    "        * 100\n",
    "    )\n",
    "    print(f\"Mejora relativa en perplexity: {improvement:.2f}%\")\n",
    "else:\n",
    "    print(\"No se pudo calcular mejora relativa (perplexity base inv√°lida).\")\n",
    "\n",
    "# Simple barplot comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "barplot = sns.barplot(\n",
    "    x=[\"Base (Phi-3)\", \"Fine-tuned\"],\n",
    "    y=[metrics_base[\"perplexity\"], metrics_fine[\"perplexity\"]],\n",
    "    palette=[\"#95a5a6\", \"#2ecc71\"]\n",
    ")\n",
    "\n",
    "# Annotate bar values\n",
    "for p in barplot.patches:\n",
    "    barplot.annotate(\n",
    "        f\"{p.get_height():.1f}\",\n",
    "        (p.get_x() + p.get_width() / 2.0, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        xytext=(0, 9),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "plt.ylim(0, 2000)\n",
    "\n",
    "plt.title(\"Comparaci√≥n de perplexity\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000077e3c223477cb0974127a96bc659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FileUploadModel",
     "state": {
      "_counter": 1,
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FileUploadModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FileUploadView",
      "accept": ".txt",
      "button_style": "",
      "data": [
       null
      ],
      "description": "Subir chat (.txt)",
      "description_tooltip": null,
      "disabled": false,
      "error": "",
      "icon": "upload",
      "layout": "IPY_MODEL_d048b13325434cdf828d5734027ee94e",
      "metadata": [
       {
        "lastModified": 1762789400422,
        "name": "chat.txt",
        "size": 5746144,
        "type": "text/plain"
       }
      ],
      "multiple": false,
      "style": "IPY_MODEL_5d736683a7da43d8a0fcf6d2e568d042"
     }
    },
    "007644d9a9654065803eb013474685b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0523b6f5933b4dd5922766a1fcba0d78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "081eac8ac59942d78338412589a88bc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0523b6f5933b4dd5922766a1fcba0d78",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c6435a321a1e4875bf63952447887b77",
      "value": "Batches:‚Äá100%"
     }
    },
    "0b0fbe7a20ca465b872fd12ba3e8a043": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d9b7e0264f04847847001bd062e75dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1244f08ba56846b392169c6b39d4ecc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14b03e931fdf4a408ff52fb0286bd58f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1514ad0ca9424e6e8cc2bbea339c6bf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "166cae34ef4742e68ee37d6d9b55204d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b89890b423249ddb03219ed985d6b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6afbafbc97a54acf9d380ae1249ca133",
       "IPY_MODEL_000077e3c223477cb0974127a96bc659",
       "IPY_MODEL_5a2fc8da6b934c85b941a5176456de43",
       "IPY_MODEL_281c39c324384aa097590eac129a3aca",
       "IPY_MODEL_1f588ccdb55e4858b356af6ba71c66b1",
       "IPY_MODEL_c09e9e96550040789e4ee73f72a62412",
       "IPY_MODEL_640f532bdc0d4fa598222c82e9cc034c"
      ],
      "layout": "IPY_MODEL_716f457b8c774135a48d0b66b9f2240a"
     }
    },
    "1ee3cdcc9c5f44aca8102fcac055fa7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f588ccdb55e4858b356af6ba71c66b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": false,
      "description": "time_gap (h):",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_8d73ef5112a346a6ac9edfe7b91b8b1c",
      "max": 24,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_386f1dc567e0401c89e32f2d2191ab35",
      "value": 3
     }
    },
    "22f9603a839a47e3a9189db8e15c321c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23c66bbba40e433f9487149dde5ef7ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b31b99f3917e4c59861357632713da86",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1244f08ba56846b392169c6b39d4ecc9",
      "value": "‚Äá14831/14831‚Äá[00:04&lt;00:00,‚Äá3085.26‚Äáexamples/s]"
     }
    },
    "281c39c324384aa097590eac129a3aca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": false,
      "description": "k_history:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_64a1f1d0ac8c4a22bb0ecbd53b6fa308",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_606382c47400446686a6ac8faca34364",
      "value": 4
     }
    },
    "37066bd6b5dd4a96adf4dde0f00d0249": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "60%"
     }
    },
    "386f1dc567e0401c89e32f2d2191ab35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "38a1ffb2e99047f18f80780e21da2e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3df323df78aa4b92a202dadfc96ce075": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4440cab6284145629c7bb21906b0dd08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_731ab9c47cad4cb0b2376f97f270d3c7",
      "max": 14831,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_166cae34ef4742e68ee37d6d9b55204d",
      "value": 14831
     }
    },
    "44de7c02ff9f4db78d3a83392220e4b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ccc4bb50c9d4a93a95f3db1cdc4363c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eaf0a883b0c24044ad7444452a57a5df",
       "IPY_MODEL_5baf19d9a1c34043aa6a7b9bac84aa24",
       "IPY_MODEL_d1086cde5e554ce48cdad8a7994cec43"
      ],
      "layout": "IPY_MODEL_50a3c9e3797b4f529f107aa67bd59797"
     }
    },
    "4d78106f1c194d55983b58c1e44383b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44de7c02ff9f4db78d3a83392220e4b1",
      "max": 671,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f39d1805738418b929132e9d57d66b3",
      "value": 671
     }
    },
    "50a3c9e3797b4f529f107aa67bd59797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54b5173fa8674eb9b1102bf9d459cad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55a5d08862dd446595c68ed061dcd860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a2fc8da6b934c85b941a5176456de43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Autor:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_37066bd6b5dd4a96adf4dde0f00d0249",
      "placeholder": "Nombre exactamente como figura en el chat",
      "style": "IPY_MODEL_54b5173fa8674eb9b1102bf9d459cad8",
      "value": "Nico Bazan"
     }
    },
    "5baf19d9a1c34043aa6a7b9bac84aa24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de0fb81662ce40e58b8dd095e5e041eb",
      "max": 3708,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4297894b3bd43c4af3bdbcd491ea44f",
      "value": 3708
     }
    },
    "5d736683a7da43d8a0fcf6d2e568d042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "5dedbcbc4bdc458bb17dcac1063ed017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ff427dd866d407a871c2ee09717fb71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_081eac8ac59942d78338412589a88bc5",
       "IPY_MODEL_b740b650766d4f37a726e446d315f6df",
       "IPY_MODEL_f0918d6914844df8be487183b2406baa"
      ],
      "layout": "IPY_MODEL_97c87949d2bd49e88ccfa1f4dd9326cf"
     }
    },
    "606382c47400446686a6ac8faca34364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "63405775b29449c389d6e68f1baa7d58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640f532bdc0d4fa598222c82e9cc034c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_95141b2d7da843b6bb6c63a2021acf7b",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Procesando chat (k-turns con roles)...\n"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Total de turnos agrupados: 47431\n",
         "Total de pares generados: 22672\n",
         "Pares generados: 22672\n",
         "\n",
         "Ejemplo de PROMPT:\n",
         "<|talk|><|ax1|> [OTRO] de vuelta mil gracias por traerme <|ax2|>\n",
         "\n",
         "Ejemplo de RESPONSE:\n",
         " de nada lolaa <|msg_sep|> no tengas verg√ºenza, no queremos q te vuelvas sola <|msg_sep|> ta peligroso <|msg_sep|> no nos cuesta nada, ni ami ni a juan <|msg_sep|> posta <|endoftext|>\n",
         "\n",
         "Variables disponibles para las siguientes celdas: 'prompts', 'responses'.\n"
        ]
       }
      ]
     }
    },
    "64a1f1d0ac8c4a22bb0ecbd53b6fa308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6afbafbc97a54acf9d380ae1249ca133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63405775b29449c389d6e68f1baa7d58",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_22f9603a839a47e3a9189db8e15c321c",
      "value": "<b>Procesamiento interactivo del chat de WhatsApp</b>"
     }
    },
    "6f39d1805738418b929132e9d57d66b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fcadb3d803a4242867e482192a54a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3385ca7ad084b76b54bd792c5c12ecc",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b37c77039daa4165ace0be1507c4124c",
      "value": "Generating‚Äátrain‚Äásplit:‚Äá"
     }
    },
    "7089428aff0b4bafb56fde74ecd2c3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "716f457b8c774135a48d0b66b9f2240a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7261dd8dcb8642a5af09d438949f92eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fcadb3d803a4242867e482192a54a8d",
       "IPY_MODEL_f34d3b82ee69493d875fb0e6e5c4e279",
       "IPY_MODEL_974cdc2c42ed478eb7fe57b297ea5d8d"
      ],
      "layout": "IPY_MODEL_1ee3cdcc9c5f44aca8102fcac055fa7b"
     }
    },
    "731ab9c47cad4cb0b2376f97f270d3c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "757b8d1a630d472ebded8cc6d0ae2c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afa75f5ab2c4797b3bf7040d420a9f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee5a23335ed2409896ba872cf65a8de2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_0d9b7e0264f04847847001bd062e75dc",
      "value": "Map:‚Äá100%"
     }
    },
    "8d73ef5112a346a6ac9edfe7b91b8b1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95141b2d7da843b6bb6c63a2021acf7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "974cdc2c42ed478eb7fe57b297ea5d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_757b8d1a630d472ebded8cc6d0ae2c7d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_38a1ffb2e99047f18f80780e21da2e09",
      "value": "‚Äá18539/0‚Äá[00:00&lt;00:00,‚Äá78506.35‚Äáexamples/s]"
     }
    },
    "97c87949d2bd49e88ccfa1f4dd9326cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7d44eeadec440b885db0b3266aff313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7afa75f5ab2c4797b3bf7040d420a9f1",
       "IPY_MODEL_4440cab6284145629c7bb21906b0dd08",
       "IPY_MODEL_23c66bbba40e433f9487149dde5ef7ad"
      ],
      "layout": "IPY_MODEL_c621cce4af43498c86a9db93fa37d9d2"
     }
    },
    "a8111075fbd045b7a04864291fb79ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b31b99f3917e4c59861357632713da86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37c77039daa4165ace0be1507c4124c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3880be52dd04da1830ba8537b92efe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3cd5c2b87d745d489eaa52d8d9e354e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14b03e931fdf4a408ff52fb0286bd58f",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d91cc7a0aaf743b4aeff8be2958d7464",
      "value": "‚Äá671/671‚Äá[00:17&lt;00:00,‚Äá67.85it/s]"
     }
    },
    "b740b650766d4f37a726e446d315f6df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df323df78aa4b92a202dadfc96ce075",
      "max": 671,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55a5d08862dd446595c68ed061dcd860",
      "value": 671
     }
    },
    "c09e9e96550040789e4ee73f72a62412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "primary",
      "description": "Procesar chat",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_e2f56bcb29b046fc88286e440da594cb",
      "style": "IPY_MODEL_1514ad0ca9424e6e8cc2bbea339c6bf6",
      "tooltip": ""
     }
    },
    "c3f3f23759714a02b0c4a11ffcef09d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f306d239ed9047ddbae48e830ff0e6c7",
       "IPY_MODEL_4d78106f1c194d55983b58c1e44383b5",
       "IPY_MODEL_b3cd5c2b87d745d489eaa52d8d9e354e"
      ],
      "layout": "IPY_MODEL_d71a7989630f41c6811674058b2a1a5b"
     }
    },
    "c621cce4af43498c86a9db93fa37d9d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6435a321a1e4875bf63952447887b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6b5b1bb6987432fa77a40789433950e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d048b13325434cdf828d5734027ee94e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1086cde5e554ce48cdad8a7994cec43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6b5b1bb6987432fa77a40789433950e",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_007644d9a9654065803eb013474685b7",
      "value": "‚Äá3708/3708‚Äá[00:01&lt;00:00,‚Äá3138.19‚Äáexamples/s]"
     }
    },
    "d4297894b3bd43c4af3bdbcd491ea44f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d71a7989630f41c6811674058b2a1a5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d91cc7a0aaf743b4aeff8be2958d7464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de0fb81662ce40e58b8dd095e5e041eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e254882eeb8443658a6f037d654f0032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f56bcb29b046fc88286e440da594cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eabf5e94e97a4cd5aeb7993498bdb3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eaf0a883b0c24044ad7444452a57a5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7089428aff0b4bafb56fde74ecd2c3e5",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_eabf5e94e97a4cd5aeb7993498bdb3b2",
      "value": "Map:‚Äá100%"
     }
    },
    "eda887369c4d450f855ebecc8bfb3f4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ee5a23335ed2409896ba872cf65a8de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0918d6914844df8be487183b2406baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e254882eeb8443658a6f037d654f0032",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5dedbcbc4bdc458bb17dcac1063ed017",
      "value": "‚Äá671/671‚Äá[00:39&lt;00:00,‚Äá44.15it/s]"
     }
    },
    "f306d239ed9047ddbae48e830ff0e6c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b0fbe7a20ca465b872fd12ba3e8a043",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b3880be52dd04da1830ba8537b92efe7",
      "value": "Batches:‚Äá100%"
     }
    },
    "f3385ca7ad084b76b54bd792c5c12ecc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f34d3b82ee69493d875fb0e6e5c4e279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eda887369c4d450f855ebecc8bfb3f4b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8111075fbd045b7a04864291fb79ef3",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
