{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "V9A2tnuoYt0y",
   "metadata": {
    "id": "V9A2tnuoYt0y"
   },
   "source": [
    "## Instalación de dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "824151c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "824151c9",
    "outputId": "7f365b5f-9c47-4cf0-c418-41db1053459f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.13/site-packages (4.4.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.13/site-packages (3.10.8)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (4.57.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (2.7.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (1.16.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (0.36.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.13/site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.13/site-packages (from transformers<6.0.0,>=4.41.0->sentence_transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/conda/lib/python3.13/site-packages (from datasets) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/conda/lib/python3.13/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.13/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/conda/lib/python3.13/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.13/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /opt/conda/lib/python3.13/site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.13/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.13/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.13/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.13/site-packages (from requests->transformers<6.0.0,>=4.41.0->sentence_transformers) (2.6.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/rocm6.3\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.13/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.13/site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in /opt/conda/lib/python3.13/site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.13/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.13/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.13/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.13/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.13/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.13/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.13/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.13/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.13/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.13/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.13/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.13/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /opt/conda/lib/python3.13/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.13/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.13/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.13/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.13/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /opt/conda/lib/python3.13/site-packages (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (7.1.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (2.7.1+cu118)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.13/site-packages (from accelerate>=0.26.0) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2025.10.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.13/site-packages (from huggingface_hub>=0.21.0->accelerate>=0.26.0) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.6)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (11.8.86)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/conda/lib/python3.13/site-packages (from torch>=2.0.0->accelerate>=0.26.0) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.26.0) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.13/site-packages (from requests->huggingface_hub>=0.21.0->accelerate>=0.26.0) (2025.11.12)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install core libraries for text modeling and evaluation\n",
    "%pip install sentence_transformers datasets matplotlib seaborn\n",
    "\n",
    "# Install PyTorch nightly build for ROCm 6.3 (GPU support on AMD)\n",
    "%pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/rocm6.3\n",
    "\n",
    "# Install Accelerate for efficient training and device management\n",
    "%pip install \"accelerate>=0.26.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56f4d9ee-362b-4add-bf45-1006f4133b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Use a single GPU to avoid DataParallel issues in notebooks.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "# Force Accelerate to disable mixed precision (stability fix for this environment).\n",
    "os.environ[\"ACCELERATE_MIXED_PRECISION\"] = \"no\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uDGEbF-etgvz",
   "metadata": {
    "id": "uDGEbF-etgvz"
   },
   "source": [
    "## Importación de librerías\n",
    "\n",
    "Esta sección carga todas las dependencias necesarias para el procesamiento de texto, entrenamiento del modelo y utilidades auxiliares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab3ec4c",
   "metadata": {
    "id": "3ab3ec4c"
   },
   "outputs": [],
   "source": [
    "# Core utilities\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "import gc\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "# Model and training components\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "# Similarity models\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optional: ensure plots render consistently\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pzmVZes_t0LW",
   "metadata": {
    "id": "pzmVZes_t0LW"
   },
   "source": [
    "## Configuración del dispositivo (CPU / GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1773a86a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1773a86a",
    "outputId": "a0eb0b4c-4079-4bb5-915b-1d5a2774f5e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo seleccionado: cuda\n",
      "GPU: NVIDIA A30 — Compute Capability: (8, 0)\n"
     ]
    }
   ],
   "source": [
    "# Detect compute device (GPU if available, otherwise CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Dispositivo seleccionado: {device}\")\n",
    "\n",
    "# Optional: print GPU details when available\n",
    "if device.type == \"cuda\":\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_cap = torch.cuda.get_device_capability(0)\n",
    "    print(f\"GPU: {gpu_name} — Compute Capability: {gpu_cap}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NkRo-9meuHoy",
   "metadata": {
    "id": "NkRo-9meuHoy"
   },
   "source": [
    "## Parámetros y filtros de datos irrelevantes\n",
    "\n",
    "En esta sección se definen patrones típicos de WhatsApp que deben ser descartados durante la limpieza del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a68a44de",
   "metadata": {
    "id": "a68a44de"
   },
   "outputs": [],
   "source": [
    "# Set of patterns considered irrelevant for training (WhatsApp system messages)\n",
    "irrelevant_data = {\n",
    "    # Spanish\n",
    "    \"eliminaste este mensaje\",\n",
    "    \"se eliminó este mensaje\",\n",
    "    \"<multimedia omitido>\",\n",
    "    \"multimedia omitido\",\n",
    "    \"los mensajes y las llamadas están cifrados de extremo a extremo\",\n",
    "\n",
    "    # English\n",
    "    \"you deleted this message\",\n",
    "    \"this message was deleted\",\n",
    "    \"<media omitted>\",\n",
    "    \"media omitted\",\n",
    "    \"messages and calls are end-to-end encrypted\",\n",
    "}\n",
    "\n",
    "def contains_irrelevant_data(message: str) -> bool:\n",
    "    \"\"\"\n",
    "    Returns True if the message contains any irrelevant WhatsApp system string.\n",
    "    Assumes the input message has already been lowercased.\n",
    "    \"\"\"\n",
    "    return any(pattern in message for pattern in irrelevant_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llnn1BwUxSWH",
   "metadata": {
    "id": "llnn1BwUxSWH"
   },
   "source": [
    "## Procesamiento del chat de WhatsApp\n",
    "\n",
    "Esta celda contiene todas las funciones relacionadas con la limpieza, parseo y estructuración del chat de WhatsApp. No realiza acciones por sí misma; solo define el procesamiento que luego será utilizado por la interfaz interactiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41b28c9b",
   "metadata": {
    "id": "41b28c9b"
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4️⃣ PROCESAMIENTO DEL CHAT WHATSAPP (k-turns con roles)\n",
    "# ============================================================\n",
    "\n",
    "MSG_SEP = \"<|msg_sep|>\"   # separator between messages inside the same turn\n",
    "\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Apply light text cleaning: lowercase, trim, remove unusual symbols,\n",
    "    normalize whitespace. This function does not decide whether a message\n",
    "    is irrelevant; that is handled by `contains_irrelevant_data`.\n",
    "    \"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^a-záéíóúñü0-9,.;:¡!¿?\\s']\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def parse_datetime(line: str):\n",
    "    \"\"\"\n",
    "    Extract the datetime of a WhatsApp message line if present.\n",
    "    Returns a datetime object or None if no valid timestamp is found.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"(\\d+/\\d+/\\d+[, ]\\s?\\d+:\\d+)\\s-\", line)\n",
    "    if match:\n",
    "        for fmt in (\"%d/%m/%y %H:%M\", \"%d/%m/%Y %H:%M\"):\n",
    "            try:\n",
    "                return datetime.strptime(match.group(1).replace(\",\", \"\"), fmt)\n",
    "            except Exception:\n",
    "                pass\n",
    "    return None\n",
    "\n",
    "\n",
    "def group_consecutive_messages(messages):\n",
    "    \"\"\"\n",
    "    Group consecutive messages from the same author into a single turn\n",
    "    if they are close in time.\n",
    "\n",
    "    When several messages from the same author are grouped, the MSG_SEP\n",
    "    token is inserted between them:\n",
    "\n",
    "        msg_1 <|msg_sep|> msg_2 <|msg_sep|> msg_3\n",
    "    \"\"\"\n",
    "    grouped = []\n",
    "    for author, msg, ts in messages:\n",
    "        if (\n",
    "            grouped\n",
    "            and grouped[-1][0] == author\n",
    "            and ts and grouped[-1][2]\n",
    "            and (ts - grouped[-1][2]) < timedelta(hours=1)\n",
    "        ):\n",
    "            # Same author and close in time → same turn with separator\n",
    "            prev_author, prev_msg, prev_ts = grouped[-1]\n",
    "            new_msg = prev_msg + f\" {MSG_SEP} \" + msg\n",
    "            grouped[-1] = (author, new_msg, ts)\n",
    "        else:\n",
    "            grouped.append((author, msg, ts))\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def process_whatsapp_chat_with_roles(\n",
    "    filepath: str,\n",
    "    target_author: str,\n",
    "    k_history: int = 4,\n",
    "    time_gap: timedelta = timedelta(hours=3),\n",
    "):\n",
    "    \"\"\"\n",
    "    Build <PROMPT, RESPONSE> pairs from a WhatsApp export.\n",
    "\n",
    "    Turns are defined as consecutive messages from the same author,\n",
    "    grouped when they are close in time.\n",
    "\n",
    "    For each turn where `target_author` speaks, up to `k_history` previous\n",
    "    turns (both authors) are used as context.\n",
    "\n",
    "    Roles are made explicit as [target_author] / [OTRO] in the prompt, and messages\n",
    "    inside each turn are separated by MSG_SEP (<|msg_sep|>).\n",
    "\n",
    "    Final format:\n",
    "\n",
    "        PROMPT   = \"<|talk|><|ax1|> [OTRO] ... <|msg_sep|> ... [target_author] ... <|ax2|>\"\n",
    "        RESPONSE = \" target_author_reply <|endoftext|>\"\n",
    "    \"\"\"\n",
    "    print(\"Procesando chat (k-turns con roles)...\")\n",
    "\n",
    "    # --- Read and parse raw lines ---\n",
    "    messages = []\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            ts = parse_datetime(line)\n",
    "            match = re.match(r\"\\d+/\\d+/\\d+[, ]\\s?\\d+:\\d+\\s-\\s([^:]+):\\s(.+)\", line)\n",
    "            if match:\n",
    "                author = match.group(1).strip()\n",
    "                raw_msg = match.group(2)\n",
    "                msg = clean_text(raw_msg)\n",
    "                # Filter empty messages or irrelevant WhatsApp system text\n",
    "                if msg and not contains_irrelevant_data(msg):\n",
    "                    messages.append((author, msg, ts))\n",
    "\n",
    "    if not messages:\n",
    "        print(\"No se encontraron mensajes válidos.\")\n",
    "        return [], []\n",
    "\n",
    "    # --- Group consecutive messages from the same author (turns) ---\n",
    "    messages = group_consecutive_messages(messages)\n",
    "    print(f\"Total de turnos agrupados: {len(messages)}\")\n",
    "\n",
    "    prompts, responses = [], []\n",
    "\n",
    "    # --- Iterate over turns and build training pairs ---\n",
    "    for i in range(1, len(messages)):\n",
    "        author_i, msg_i, ts_i = messages[i]\n",
    "\n",
    "        # We only care about turns where the target author is responding\n",
    "        if author_i != target_author:\n",
    "            continue\n",
    "\n",
    "        # Build a context of up to k_history previous turns (both authors)\n",
    "        context = []\n",
    "        last_ts = ts_i\n",
    "\n",
    "        for j in range(i - 1, -1, -1):\n",
    "            a_j, m_j, ts_j = messages[j]\n",
    "\n",
    "            # Session break if the time gap is too large\n",
    "            if ts_j and last_ts and (last_ts - ts_j) > time_gap:\n",
    "                break\n",
    "\n",
    "            # Insert at the beginning to keep chronological order\n",
    "            context.insert(0, (a_j, m_j))\n",
    "            last_ts = ts_j if ts_j is not None else last_ts\n",
    "\n",
    "            if len(context) >= k_history:\n",
    "                break\n",
    "\n",
    "        if not context:\n",
    "            continue\n",
    "\n",
    "        def fmt_turn(a, m):\n",
    "            speaker = f\"[{target_author}]\" if a == target_author else \"[OTRO]\"\n",
    "            return f\"{speaker} {m}\"\n",
    "\n",
    "        context_str = \" \".join(fmt_turn(a, m) for (a, m) in context)\n",
    "\n",
    "        prompt = f\"<|talk|><|ax1|> {context_str} <|ax2|>\"\n",
    "        response = f\" {msg_i} <|endoftext|>\"\n",
    "\n",
    "        prompts.append(prompt)\n",
    "        responses.append(response)\n",
    "\n",
    "    print(f\"Total de pares generados: {len(prompts)}\")\n",
    "    return prompts, responses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QQ62_LUHxkq8",
   "metadata": {
    "id": "QQ62_LUHxkq8"
   },
   "source": [
    "## Procesamiento interactivo del chat\n",
    "Esta celda ofrece una interfaz interactiva para cargar el archivo del chat, ingresar el nombre del autor y ajustar parámetros como el historial considerado y el tiempo máximo entre mensajes. Permite procesar el chat sin modificar código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3jEMtLjsvUt6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428,
     "referenced_widgets": [
      "1b89890b423249ddb03219ed985d6b62",
      "6afbafbc97a54acf9d380ae1249ca133",
      "000077e3c223477cb0974127a96bc659",
      "5a2fc8da6b934c85b941a5176456de43",
      "281c39c324384aa097590eac129a3aca",
      "1f588ccdb55e4858b356af6ba71c66b1",
      "c09e9e96550040789e4ee73f72a62412",
      "640f532bdc0d4fa598222c82e9cc034c",
      "716f457b8c774135a48d0b66b9f2240a",
      "63405775b29449c389d6e68f1baa7d58",
      "22f9603a839a47e3a9189db8e15c321c",
      "d048b13325434cdf828d5734027ee94e",
      "5d736683a7da43d8a0fcf6d2e568d042",
      "37066bd6b5dd4a96adf4dde0f00d0249",
      "54b5173fa8674eb9b1102bf9d459cad8",
      "64a1f1d0ac8c4a22bb0ecbd53b6fa308",
      "606382c47400446686a6ac8faca34364",
      "8d73ef5112a346a6ac9edfe7b91b8b1c",
      "386f1dc567e0401c89e32f2d2191ab35",
      "e2f56bcb29b046fc88286e440da594cb",
      "1514ad0ca9424e6e8cc2bbea339c6bf6",
      "95141b2d7da843b6bb6c63a2021acf7b"
     ]
    },
    "id": "3jEMtLjsvUt6",
    "outputId": "a644317b-7070-4cd6-ec79-0c055d96c4f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200d38e066b14df0836aa2ada09080a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<b>Procesamiento interactivo del chat de WhatsApp</b>'), FileUpload(value=(), accep…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# File upload widget for WhatsApp chat export (.txt)\n",
    "chat_uploader = widgets.FileUpload(\n",
    "    accept=\".txt\",\n",
    "    multiple=False,\n",
    "    description=\"Subir chat (.txt)\"\n",
    ")\n",
    "\n",
    "# Text input for the target author (exactly as appears in the export)\n",
    "author_input = widgets.Text(\n",
    "    description=\"Autor:\",\n",
    "    placeholder=\"Nombre exactamente como figura en el chat\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "# Slider for the number of history turns\n",
    "k_history_slider = widgets.IntSlider(\n",
    "    value=4,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description=\"k_history:\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Slider for the time gap (in hours) to cut sessions\n",
    "time_gap_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=24,\n",
    "    step=1,\n",
    "    description=\"time_gap (h):\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Button to trigger processing\n",
    "process_button = widgets.Button(\n",
    "    description=\"Procesar chat\",\n",
    "    button_style=\"primary\"\n",
    ")\n",
    "\n",
    "output_proc = widgets.Output()\n",
    "\n",
    "\n",
    "def on_process_clicked(_):\n",
    "    with output_proc:\n",
    "        clear_output()\n",
    "\n",
    "        # Basic validation\n",
    "        if len(chat_uploader.value) == 0:\n",
    "            print(\"Por favor, sube un archivo de chat en formato .txt.\")\n",
    "            return\n",
    "\n",
    "        target_author = author_input.value.strip()\n",
    "        if not target_author:\n",
    "            print(\"Por favor, ingresa el nombre del autor exactamente como aparece en el chat.\")\n",
    "            return\n",
    "\n",
    "        # Extract uploaded file content\n",
    "        upload_info = chat_uploader.value[0]\n",
    "        content = bytes(upload_info[\"content\"]).decode(\"utf-8-sig\", errors=\"replace\")\n",
    "\n",
    "        # Save to temporary file so we can reuse the existing function\n",
    "        tmp_path = \"uploaded_chat.txt\"\n",
    "        with open(tmp_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(content)\n",
    "\n",
    "        # Call the processing function and expose results as global variables\n",
    "        global prompts, responses\n",
    "        prompts, responses = process_whatsapp_chat_with_roles(\n",
    "            filepath=tmp_path,\n",
    "            target_author=target_author,\n",
    "            k_history=k_history_slider.value,\n",
    "            time_gap=timedelta(hours=time_gap_slider.value),\n",
    "        )\n",
    "\n",
    "        print(f\"Pares generados: {len(prompts)}\")\n",
    "        if prompts:\n",
    "            print(\"\\nEjemplo de PROMPT:\")\n",
    "            print(prompts[0][:500] + (\"...\" if len(prompts[0]) > 500 else \"\"))\n",
    "            print(\"\\nEjemplo de RESPONSE:\")\n",
    "            print(responses[0][:500] + (\"...\" if len(responses[0]) > 500 else \"\"))\n",
    "        print(\"\\nVariables disponibles para las siguientes celdas: 'prompts', 'responses'.\")\n",
    "\n",
    "\n",
    "process_button.on_click(on_process_clicked)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HTML(\"<b>Procesamiento interactivo del chat de WhatsApp</b>\"),\n",
    "        chat_uploader,\n",
    "        author_input,\n",
    "        k_history_slider,\n",
    "        time_gap_slider,\n",
    "        process_button,\n",
    "        output_proc\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KaSrQwXWzBjQ",
   "metadata": {
    "id": "KaSrQwXWzBjQ"
   },
   "source": [
    "## Creación del dataset, limpieza y guardado\n",
    "\n",
    "Esta celda toma las listas prompts y responses generadas previamente, construye un DataFrame, aplica una limpieza básica (elimina ejemplos triviales y enlaces) y guarda un archivo CSV con el dataset inicial. Además, muestra algunos ejemplos aleatorios para inspeccionar el resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fc350a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fc350a0",
    "outputId": "7f0b04b3-6948-46b1-ca32-da576d1f8570"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset inicial guardado → 12407 pares.\n",
      "\n",
      "Vista aleatoria de algunos ejemplos:\n",
      "\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] que cosa [OTRO] todo lo q me contaste a mi [Nico Bazan] sisi <|msg_sep|> el día de tu despedida <|msg_sep|> en teoría si le dije <|msg_sep|> no sé si se acuerda <|msg_sep|> man <|msg_sep|> me hizo quedar re mal bossio [OTRO] hablale <|ax2|>\n",
      "→ Response:\n",
      " se enterará de que lo sacaron? <|endoftext|>\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] si <|msg_sep|> ah invocaste xd <|msg_sep|> romeo te viola si [OTRO] invoque en casi todos <|msg_sep|> ahora me arrepiento <|msg_sep|> pero puedo hacer ng [Nico Bazan] viste <|msg_sep|> yo me arrepentí en el elden <|msg_sep|> malenia la hice invocando <|msg_sep|> ahora puedo cambiar mí destino jaja <|msg_sep|> te da más satisfacción y ego <|msg_sep|> encima la mímica antes del nerf te acordas <|msg_sep|> rotaso [OTRO] igual <|msg_sep|> contra laxasia no me arrepiento para nada haber invocado <|msg_sep|> se queda corto este emoji para laxasia <|ax2|>\n",
      "→ Response:\n",
      " 3 veces me dijiste ya eso jajaja <|endoftext|>\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] xd <|msg_sep|> recien vuelve [OTRO] uhhh : [Nico Bazan] q onda <|msg_sep|> xd <|msg_sep|> rip? [OTRO] xd <|msg_sep|> me saqué el wifi a ver si me concentraba <|msg_sep|> hice de vuelta el de agosto... pero ayudandome con el de sara <|msg_sep|> voy a hacer el de septiembre <|msg_sep|> y veo realmente q onda <|msg_sep|> si son parecidos ya sabría más o menos como <|msg_sep|> pero si no lo son... vo <|msg_sep|> : <|ax2|>\n",
      "→ Response:\n",
      " veremos <|msg_sep|> mañana me levanto temprano y decido q hacer xd <|endoftext|>\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] ta mas linda belu que meli xd [OTRO] ajajjajaja <|msg_sep|> puede ser si <|msg_sep|> a mi belu me cayó re bien <|msg_sep|> pero para bien o para mal? <|ax2|>\n",
      "→ Response:\n",
      " tengo 1 kg menos pero menos grasa creo <|msg_sep|> asiq bien <|endoftext|>\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] mal <|msg_sep|> igual dice demorado [OTRO] no creo q se juegue <|msg_sep|> fortnite? <|msg_sep|> si se juega <|msg_sep|> jajajaaj [Nico Bazan] jajajja <|msg_sep|> fútbol señores [OTRO] esta re picado el partido <|ax2|>\n",
      "→ Response:\n",
      " mal <|msg_sep|> gabriel jesús se tenía que ir <|msg_sep|> lo tiene que solicitar <|endoftext|>\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Safety check: prompts and responses must exist\n",
    "if \"prompts\" not in globals() or \"responses\" not in globals():\n",
    "    raise RuntimeError(\n",
    "        \"Las variables 'prompts' y 'responses' no existen. \"\n",
    "        \"Ejecuta primero el procesamiento interactivo del chat (sección 4-bis).\"\n",
    "    )\n",
    "\n",
    "def build_dataset(prompts, responses,\n",
    "                  min_prompt_len: int = 4,\n",
    "                  min_response_len: int = 3,\n",
    "                  filter_links: bool = True):\n",
    "    \"\"\"\n",
    "    Build a DataFrame from prompts and responses applying basic cleaning:\n",
    "    - Drop NaN values.\n",
    "    - Remove very short prompts/responses.\n",
    "    - Optionally filter out examples containing URLs.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame({\"prompt\": prompts, \"response\": responses}).dropna()\n",
    "\n",
    "    # Filter trivial examples (very short prompts/responses)\n",
    "    df = df[\n",
    "        (df[\"prompt\"].str.split().str.len() >= min_prompt_len) &\n",
    "        (df[\"response\"].str.split().str.len() >= min_response_len)\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    # Basic noise filtering: remove URLs if requested\n",
    "    if filter_links:\n",
    "        df = df[\n",
    "            ~df[\"prompt\"].str.contains(r\"http|www|\\.com\", regex=True) &\n",
    "            ~df[\"response\"].str.contains(r\"http|www|\\.com\", regex=True)\n",
    "        ].reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Default parameters (aligned with your original thresholds)\n",
    "min_prompt_len_default = 4\n",
    "min_response_len_default = 3\n",
    "filter_links_default = True\n",
    "output_path_default = \"train_data_raw.csv\"\n",
    "\n",
    "# Build dataset with default configuration\n",
    "data = build_dataset(\n",
    "    prompts,\n",
    "    responses,\n",
    "    min_prompt_len=min_prompt_len_default,\n",
    "    min_response_len=min_response_len_default,\n",
    "    filter_links=filter_links_default,\n",
    ")\n",
    "\n",
    "# Save preprocessed dataset\n",
    "output_path = output_path_default\n",
    "data.to_csv(output_path, index=False, quoting=csv.QUOTE_ALL)\n",
    "\n",
    "print(f\"Dataset inicial guardado → {len(data)} pares.\")\n",
    "print(\"\\nVista aleatoria de algunos ejemplos:\\n\")\n",
    "for _ in range(min(5, len(data))):\n",
    "    s = data.sample(1).iloc[0]\n",
    "    print(f\"Prompt:\\n{s['prompt']}\\n→ Response:\\n{s['response']}\\n{'-'*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0MLkir1uzpxw",
   "metadata": {
    "id": "0MLkir1uzpxw"
   },
   "source": [
    "## Filtrado semántico global\n",
    "\n",
    "Esta celda aplica un filtrado semántico basado en embeddings para quedarse únicamente con pares prompt–response que tengan una relación de significado suficientemente fuerte. Se calcula la similitud coseno entre cada prompt y su respuesta, se agregan estos valores al DataFrame y se guarda un dataset filtrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0115728a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 539,
     "referenced_widgets": [
      "5ff427dd866d407a871c2ee09717fb71",
      "081eac8ac59942d78338412589a88bc5",
      "b740b650766d4f37a726e446d315f6df",
      "f0918d6914844df8be487183b2406baa",
      "97c87949d2bd49e88ccfa1f4dd9326cf",
      "0523b6f5933b4dd5922766a1fcba0d78",
      "c6435a321a1e4875bf63952447887b77",
      "3df323df78aa4b92a202dadfc96ce075",
      "55a5d08862dd446595c68ed061dcd860",
      "e254882eeb8443658a6f037d654f0032",
      "5dedbcbc4bdc458bb17dcac1063ed017",
      "c3f3f23759714a02b0c4a11ffcef09d6",
      "f306d239ed9047ddbae48e830ff0e6c7",
      "4d78106f1c194d55983b58c1e44383b5",
      "b3cd5c2b87d745d489eaa52d8d9e354e",
      "d71a7989630f41c6811674058b2a1a5b",
      "0b0fbe7a20ca465b872fd12ba3e8a043",
      "b3880be52dd04da1830ba8537b92efe7",
      "44de7c02ff9f4db78d3a83392220e4b1",
      "6f39d1805738418b929132e9d57d66b3",
      "14b03e931fdf4a408ff52fb0286bd58f",
      "d91cc7a0aaf743b4aeff8be2958d7464"
     ]
    },
    "id": "0115728a",
    "outputId": "ea133d03-fb6f-4c28-bbb9-2f40b7235a64"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5645aac14ec948f7b6bae09c3aee28e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d651f5a03cc447f8ebc44447d692919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de similitud: 0.451\n",
      "Dataset final guardado en 'filtered_train_data.csv'.\n",
      "Total de pares útiles: 10592 (de 12407).\n",
      "\n",
      "Vista rápida de algunos ejemplos filtrados:\n",
      "\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] mm no estoy seguro pero que creo son equivalentes <|msg_sep|> que tienen siempre el mismo valor de verdad? creo que era algo asi [OTRO] aaa... espero no me rete el profe is le pregunto eso [Nico Bazan] la f no tiene nada que ver con las constantes? porque pensas que es verdad? <|msg_sep|> no es para retartr si no para entender tu razonamiento xd [OTRO] aah porq es relación y no función? creo q flashé q era función tot <|msg_sep|> ou : y cual sería el dom de esta función? no lo sabemos o vacío? <|ax2|>\n",
      "→ Response:\n",
      " creo q no sabemos <|msg_sep|> jaja <|endoftext|>\n",
      "Similarity: 0.534\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] es que no me atrae sexualmente, es difícil así jajaja [OTRO] sisi me imagino [Nico Bazan] si la cara fuese más o menos y el cuerpo bien ya fue <|msg_sep|> es naturaleza jajaja que se yo no me puedo inventar o imaginar cosas <|msg_sep|> lo peor es que como hablamos hace como un mes no puedo ghostearla <|msg_sep|> le voy a seguir hablando pero si sale el tema le voy a dejar en claro que no quiero nada [OTRO] sisi <|msg_sep|> temprano <|ax2|>\n",
      "→ Response:\n",
      " no te quedas después? <|msg_sep|> aunque se quede bossio <|endoftext|>\n",
      "Similarity: 0.379\n",
      "----------------------------------------------------------------------\n",
      "Prompt:\n",
      "<|talk|><|ax1|> [Nico Bazan] pero no puedo usar la otra mochila [OTRO] pero podemos craftear la heladera grande del mod <|msg_sep|> y listo [Nico Bazan] yo llevo la comida y vos lleva la mochila <|msg_sep|> osea llevo mí mochila para comida [OTRO] igual es ir a romper los montículos de chatarra esos <|msg_sep|> con suerte nada más <|ax2|>\n",
      "→ Response:\n",
      " no sé si nos conviene ir juntos o separados <|msg_sep|> en cuevas separadas <|endoftext|>\n",
      "Similarity: 0.333\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load the sentence transformer model (only once)\n",
    "if \"model_emb\" not in globals():\n",
    "    model_emb = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Encode prompts and responses\n",
    "emb_prompts = model_emb.encode(\n",
    "    data[\"prompt\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "emb_resps = model_emb.encode(\n",
    "    data[\"response\"].tolist(),\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "# Cosine similarity between each prompt and its paired response\n",
    "similarities = util.cos_sim(emb_prompts, emb_resps).diagonal().cpu().numpy()\n",
    "data[\"similarity\"] = similarities\n",
    "\n",
    "print(f\"Media de similitud: {data['similarity'].mean():.3f}\")\n",
    "\n",
    "# Filtering configuration\n",
    "SIM_THRESHOLD = 0.30\n",
    "MAX_PROMPT_LEN = 600\n",
    "MAX_RESPONSE_LEN = 400\n",
    "\n",
    "# Keep only examples with strong semantic relation and reasonable length\n",
    "filtered = data[\n",
    "    (data[\"similarity\"] > SIM_THRESHOLD) &\n",
    "    (data[\"prompt\"].str.len() < MAX_PROMPT_LEN) &\n",
    "    (data[\"response\"].str.len() < MAX_RESPONSE_LEN)\n",
    "].reset_index(drop=True)\n",
    "\n",
    "output_filtered_path = \"filtered_train_data.csv\"\n",
    "filtered.to_csv(output_filtered_path, index=False)\n",
    "\n",
    "print(f\"Dataset final guardado en '{output_filtered_path}'.\")\n",
    "print(f\"Total de pares útiles: {len(filtered)} (de {len(data)}).\")\n",
    "\n",
    "# Quick preview of filtered examples\n",
    "print(\"\\nVista rápida de algunos ejemplos filtrados:\\n\")\n",
    "for _ in range(min(3, len(filtered))):\n",
    "    s = filtered.sample(1).iloc[0]\n",
    "    print(\n",
    "        f\"Prompt:\\n{s['prompt']}\\n\"\n",
    "        f\"→ Response:\\n{s['response']}\\n\"\n",
    "        f\"Similarity: {s['similarity']:.3f}\\n\"\n",
    "        + \"-\" * 70\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kk45qHjk1flR",
   "metadata": {
    "id": "kk45qHjk1flR"
   },
   "source": [
    "## Carga del modelo base o fine-tune anterior\n",
    "\n",
    "Esta celda carga el modelo base seleccionado, inicializa el tokenizer, registra los tokens especiales utilizados en el formato de conversación y ajusta las dimensiones del modelo para incluirlos. Finalmente, mueve el modelo al dispositivo correspondiente (CPU o GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f05cee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2f05cee",
    "outputId": "2de6f629-00e5-44e5-baea-2fa7022bbf6b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: DeepESP/gpt2-spanish\n",
      "Total de tokens en el tokenizer: 50260\n",
      "Ejecutando en: cuda\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7️⃣ CARGA DEL MODELO BASE O FINE-TUNE ANTERIOR\n",
    "# ============================================================\n",
    "model_name = \"DeepESP/gpt2-spanish\"\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Register special tokens used in the conversational format\n",
    "special_tokens = {\n",
    "    \"additional_special_tokens\": [MSG_SEP, f\"[{author_input.value.strip()}]\", \"[OTRO]\"]\n",
    "}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# Padding token (GPT-2 uses EOS as pad)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Resize embeddings to include new special tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Move model to CPU/GPU\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Modelo cargado: {model_name}\")\n",
    "print(f\"Total de tokens en el tokenizer: {len(tokenizer)}\")\n",
    "print(f\"Ejecutando en: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vd_KTL_E3pSU",
   "metadata": {
    "id": "vd_KTL_E3pSU"
   },
   "source": [
    "## Tokenización robusta para entrenamiento\n",
    "\n",
    "Esta celda carga el dataset filtrado, separa los datos en entrenamiento y validación, y construye una función de tokenización adecuada para entrenamiento causal (SFT). Cada ejemplo se tokeniza de manera independiente (sin concatenación), y las etiquetas (labels) corresponden directamente a los input_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2852a42e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296,
     "referenced_widgets": [
      "7261dd8dcb8642a5af09d438949f92eb",
      "6fcadb3d803a4242867e482192a54a8d",
      "f34d3b82ee69493d875fb0e6e5c4e279",
      "974cdc2c42ed478eb7fe57b297ea5d8d",
      "1ee3cdcc9c5f44aca8102fcac055fa7b",
      "f3385ca7ad084b76b54bd792c5c12ecc",
      "b37c77039daa4165ace0be1507c4124c",
      "eda887369c4d450f855ebecc8bfb3f4b",
      "a8111075fbd045b7a04864291fb79ef3",
      "757b8d1a630d472ebded8cc6d0ae2c7d",
      "38a1ffb2e99047f18f80780e21da2e09",
      "a7d44eeadec440b885db0b3266aff313",
      "7afa75f5ab2c4797b3bf7040d420a9f1",
      "4440cab6284145629c7bb21906b0dd08",
      "23c66bbba40e433f9487149dde5ef7ad",
      "c621cce4af43498c86a9db93fa37d9d2",
      "ee5a23335ed2409896ba872cf65a8de2",
      "0d9b7e0264f04847847001bd062e75dc",
      "731ab9c47cad4cb0b2376f97f270d3c7",
      "166cae34ef4742e68ee37d6d9b55204d",
      "b31b99f3917e4c59861357632713da86",
      "1244f08ba56846b392169c6b39d4ecc9",
      "4ccc4bb50c9d4a93a95f3db1cdc4363c",
      "eaf0a883b0c24044ad7444452a57a5df",
      "5baf19d9a1c34043aa6a7b9bac84aa24",
      "d1086cde5e554ce48cdad8a7994cec43",
      "50a3c9e3797b4f529f107aa67bd59797",
      "7089428aff0b4bafb56fde74ecd2c3e5",
      "eabf5e94e97a4cd5aeb7993498bdb3b2",
      "de0fb81662ce40e58b8dd095e5e041eb",
      "d4297894b3bd43c4af3bdbcd491ea44f",
      "c6b5b1bb6987432fa77a40789433950e",
      "007644d9a9654065803eb013474685b7"
     ]
    },
    "id": "2852a42e",
    "outputId": "a2cd3b30-4c8d-4e7b-8046-5936e0728653"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce04bef13a4f4105b15993f5a7771c20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d4b0593d224694b6b04e61569eb3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4be505102f5445188c874d617af408a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2119 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['similarity', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 8473\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['similarity', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 2119\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load and clean dataset\n",
    "data = pd.read_csv(\"filtered_train_data.csv\")\n",
    "data = data.dropna(subset=[\"prompt\", \"response\"])\n",
    "data = data[(data[\"prompt\"].str.strip() != \"\") & (data[\"response\"].str.strip() != \"\")]\n",
    "data.to_csv(\"filtered_train_data.csv\", index=False)\n",
    "\n",
    "# Load into HuggingFace dataset structure\n",
    "dataset = load_dataset(\"csv\", data_files=\"filtered_train_data.csv\")\n",
    "\n",
    "# Split into train/validation\n",
    "train_test = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "datasets = DatasetDict({\n",
    "    \"train\": train_test[\"train\"],\n",
    "    \"validation\": train_test[\"test\"],\n",
    "})\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    \"\"\"\n",
    "    Tokenizes each pair (prompt, response) as a single training example.\n",
    "    The full conversational formatted text is already built in the dataset.\n",
    "    Labels are set equal to input_ids for causal LM training.\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for p, r in zip(examples[\"prompt\"], examples[\"response\"]):\n",
    "        if isinstance(p, str) and isinstance(r, str):\n",
    "            texts.append(f\"{p.strip()} {r.strip()}\")\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        texts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=256,\n",
    "    )\n",
    "\n",
    "    # Causal LM: labels = input_ids\n",
    "    encodings[\"labels\"] = encodings[\"input_ids\"].copy()\n",
    "    return encodings\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized = datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"prompt\", \"response\"],\n",
    ")\n",
    "\n",
    "lm_datasets = tokenized\n",
    "print(lm_datasets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02XSq4N_4p4m",
   "metadata": {
    "id": "02XSq4N_4p4m"
   },
   "source": [
    "## Argumentos de entrenamiento\n",
    "\n",
    "Define los hiperparámetros principales de entrenamiento para el fine-tuning del modelo (número de épocas, batch size, tasa de aprendizaje, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edd80ab5",
   "metadata": {
    "id": "edd80ab5"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./nico-bot\",\n",
    "    num_train_epochs=3,              # few epochs for a final refinement\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,              # small LR to preserve base style\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"no\",        # no evaluation during training\n",
    "    logging_steps=10,\n",
    "    report_to=[],                    # disable external loggers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lXmpmSWK45fj",
   "metadata": {
    "id": "lXmpmSWK45fj"
   },
   "source": [
    "## Configuración del Trainer\n",
    "\n",
    "Configura el objeto Trainer que orquesta el loop de entrenamiento, conectando el modelo, los datos tokenizados y los argumentos de entrenamiento. Se usa el DataCollatorForLanguageModeling en modo causal (sin MLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f808f39",
   "metadata": {
    "id": "6f808f39"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    "    data_collator=DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer,\n",
    "        mlm=False,   # causal LM, not masked LM\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IOP5FaXQ5e7N",
   "metadata": {
    "id": "IOP5FaXQ5e7N"
   },
   "source": [
    "## Entrenamiento y guardado del modelo\n",
    "\n",
    "Esta celda entrena el modelo y guarda los pesos y el tokenizer en un directorio cuyo nombre se genera automáticamente en función del autor seleccionado en la etapa de procesamiento interactivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17101b70",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "17101b70",
    "outputId": "f9f5a23a-3a56-46bb-e487-5e44c20475cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardando el modelo en: ./bot_Nico_Bazan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3180/3180 14:40, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>6.754200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>6.252500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>5.879800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>5.592400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>5.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>5.351500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>5.332400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>5.291000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>5.144700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>5.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>5.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>4.959200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>4.922000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>4.894400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>4.781500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>4.754900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>4.716800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4.720200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>4.692300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>4.560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>4.499100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>4.464200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>4.466700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>4.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>4.369400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>4.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>4.242400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4.210400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>4.275300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>4.149300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>4.233700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>4.299800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>4.132400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>4.114800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>4.092800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>4.055400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>4.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>4.025300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>4.018700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>4.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>3.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>3.946700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>3.931000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>3.837400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>3.870200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>3.807900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>3.831000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.838100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>3.845100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>3.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>3.809600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>3.703800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.770800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>3.696900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>3.722700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>3.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>3.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.779800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>3.665900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>3.759700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>3.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>3.724600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>3.757400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>3.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>3.655200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>3.744200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.633700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>3.753000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>3.773600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>3.593000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>3.683400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.727000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>3.706300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>3.697800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>3.711300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>3.647400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.615400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>3.665500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>3.640200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>3.733900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>3.659700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.755700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>3.644200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>3.749800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>3.615100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>3.754600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.642100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>3.629600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>3.596300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>3.690700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>3.510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.574900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>3.640500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>3.550200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>3.585100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>3.753300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>3.573600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>3.615500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>3.645600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>3.624600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>3.590100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>3.537600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>3.474200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>3.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.542800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>3.509200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>3.567800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>3.474500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>3.614100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.504200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>3.479800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>3.483900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>3.468600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>3.466300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.504600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>3.586800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>3.580600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>3.448600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>3.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.460300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>3.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>3.455900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>3.491500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>3.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.571700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1310</td>\n",
       "      <td>3.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1320</td>\n",
       "      <td>3.454000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1330</td>\n",
       "      <td>3.571200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1340</td>\n",
       "      <td>3.467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>3.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1360</td>\n",
       "      <td>3.514900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1370</td>\n",
       "      <td>3.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1380</td>\n",
       "      <td>3.518300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1390</td>\n",
       "      <td>3.505500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1410</td>\n",
       "      <td>3.460500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1420</td>\n",
       "      <td>3.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1430</td>\n",
       "      <td>3.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1440</td>\n",
       "      <td>3.543900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>3.482900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1460</td>\n",
       "      <td>3.542900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1470</td>\n",
       "      <td>3.485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1480</td>\n",
       "      <td>3.489700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1490</td>\n",
       "      <td>3.520500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1510</td>\n",
       "      <td>3.503200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1520</td>\n",
       "      <td>3.477900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1530</td>\n",
       "      <td>3.521500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1540</td>\n",
       "      <td>3.491700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1560</td>\n",
       "      <td>3.454400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1570</td>\n",
       "      <td>3.409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1580</td>\n",
       "      <td>3.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1590</td>\n",
       "      <td>3.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.442400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1610</td>\n",
       "      <td>3.481900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1620</td>\n",
       "      <td>3.434200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1630</td>\n",
       "      <td>3.457900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1640</td>\n",
       "      <td>3.457500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.445100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1660</td>\n",
       "      <td>3.553200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1670</td>\n",
       "      <td>3.448800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1680</td>\n",
       "      <td>3.457700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>3.464800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.469100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1710</td>\n",
       "      <td>3.504800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1720</td>\n",
       "      <td>3.472800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1730</td>\n",
       "      <td>3.519700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1740</td>\n",
       "      <td>3.338600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1750</td>\n",
       "      <td>3.385500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1760</td>\n",
       "      <td>3.530700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1770</td>\n",
       "      <td>3.408900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1780</td>\n",
       "      <td>3.477800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1790</td>\n",
       "      <td>3.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.422500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1810</td>\n",
       "      <td>3.440300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1820</td>\n",
       "      <td>3.357600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>3.491900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>3.474300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1850</td>\n",
       "      <td>3.472600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1860</td>\n",
       "      <td>3.402000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1870</td>\n",
       "      <td>3.487300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1880</td>\n",
       "      <td>3.446200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1890</td>\n",
       "      <td>3.429200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.504700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1910</td>\n",
       "      <td>3.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1920</td>\n",
       "      <td>3.443800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1930</td>\n",
       "      <td>3.463800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1940</td>\n",
       "      <td>3.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1950</td>\n",
       "      <td>3.389700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1960</td>\n",
       "      <td>3.446500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1970</td>\n",
       "      <td>3.421600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1980</td>\n",
       "      <td>3.406000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1990</td>\n",
       "      <td>3.417000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.468200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2010</td>\n",
       "      <td>3.379600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2020</td>\n",
       "      <td>3.381700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2030</td>\n",
       "      <td>3.474100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2040</td>\n",
       "      <td>3.445700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2050</td>\n",
       "      <td>3.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2060</td>\n",
       "      <td>3.408400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2070</td>\n",
       "      <td>3.398000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2080</td>\n",
       "      <td>3.450400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2090</td>\n",
       "      <td>3.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2110</td>\n",
       "      <td>3.456800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2120</td>\n",
       "      <td>3.446800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2130</td>\n",
       "      <td>3.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2140</td>\n",
       "      <td>3.319900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2150</td>\n",
       "      <td>3.453400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2160</td>\n",
       "      <td>3.383200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2170</td>\n",
       "      <td>3.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2180</td>\n",
       "      <td>3.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2190</td>\n",
       "      <td>3.378000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.426400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2210</td>\n",
       "      <td>3.356200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2220</td>\n",
       "      <td>3.331700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2230</td>\n",
       "      <td>3.422000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2240</td>\n",
       "      <td>3.336000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2250</td>\n",
       "      <td>3.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2260</td>\n",
       "      <td>3.309600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2270</td>\n",
       "      <td>3.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2280</td>\n",
       "      <td>3.430700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2290</td>\n",
       "      <td>3.390900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.411600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2310</td>\n",
       "      <td>3.355700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2320</td>\n",
       "      <td>3.388500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2330</td>\n",
       "      <td>3.326000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2340</td>\n",
       "      <td>3.421900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2350</td>\n",
       "      <td>3.345800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2360</td>\n",
       "      <td>3.410800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2370</td>\n",
       "      <td>3.364100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2380</td>\n",
       "      <td>3.297200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2390</td>\n",
       "      <td>3.408200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.409200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2410</td>\n",
       "      <td>3.320800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2420</td>\n",
       "      <td>3.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2430</td>\n",
       "      <td>3.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2440</td>\n",
       "      <td>3.391300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2450</td>\n",
       "      <td>3.352900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2460</td>\n",
       "      <td>3.274600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2470</td>\n",
       "      <td>3.382800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2480</td>\n",
       "      <td>3.418500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2490</td>\n",
       "      <td>3.364900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.305800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2510</td>\n",
       "      <td>3.217100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2520</td>\n",
       "      <td>3.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2530</td>\n",
       "      <td>3.370900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2540</td>\n",
       "      <td>3.329300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2550</td>\n",
       "      <td>3.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2560</td>\n",
       "      <td>3.380400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2570</td>\n",
       "      <td>3.334300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2580</td>\n",
       "      <td>3.303600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2590</td>\n",
       "      <td>3.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.333200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2610</td>\n",
       "      <td>3.377800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2620</td>\n",
       "      <td>3.419900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2630</td>\n",
       "      <td>3.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2640</td>\n",
       "      <td>3.315900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2650</td>\n",
       "      <td>3.364200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2660</td>\n",
       "      <td>3.365700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2670</td>\n",
       "      <td>3.346600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2680</td>\n",
       "      <td>3.438600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2690</td>\n",
       "      <td>3.280300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.437400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2710</td>\n",
       "      <td>3.399800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2720</td>\n",
       "      <td>3.372100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2730</td>\n",
       "      <td>3.417400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2740</td>\n",
       "      <td>3.342900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2750</td>\n",
       "      <td>3.357300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>3.322300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2770</td>\n",
       "      <td>3.383900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2780</td>\n",
       "      <td>3.349500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2790</td>\n",
       "      <td>3.303800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2810</td>\n",
       "      <td>3.427300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2820</td>\n",
       "      <td>3.367500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2830</td>\n",
       "      <td>3.427900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2840</td>\n",
       "      <td>3.323900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2850</td>\n",
       "      <td>3.367400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2860</td>\n",
       "      <td>3.328400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2870</td>\n",
       "      <td>3.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2880</td>\n",
       "      <td>3.307700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2890</td>\n",
       "      <td>3.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.390300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2910</td>\n",
       "      <td>3.353300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2920</td>\n",
       "      <td>3.437900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2930</td>\n",
       "      <td>3.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2940</td>\n",
       "      <td>3.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2950</td>\n",
       "      <td>3.378300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2960</td>\n",
       "      <td>3.367600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2970</td>\n",
       "      <td>3.308500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2980</td>\n",
       "      <td>3.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2990</td>\n",
       "      <td>3.442800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.254500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3010</td>\n",
       "      <td>3.328800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3020</td>\n",
       "      <td>3.314300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3030</td>\n",
       "      <td>3.404200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3040</td>\n",
       "      <td>3.312700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3050</td>\n",
       "      <td>3.353200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3060</td>\n",
       "      <td>3.358900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3070</td>\n",
       "      <td>3.306600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3080</td>\n",
       "      <td>3.424900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3090</td>\n",
       "      <td>3.291600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>3.469000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3110</td>\n",
       "      <td>3.412700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3120</td>\n",
       "      <td>3.376600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3130</td>\n",
       "      <td>3.423600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3140</td>\n",
       "      <td>3.377900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3150</td>\n",
       "      <td>3.289400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3160</td>\n",
       "      <td>3.314600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3170</td>\n",
       "      <td>3.332800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3180</td>\n",
       "      <td>3.311800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo y tokenizer guardados en: ./bot_Nico_Bazan\n"
     ]
    }
   ],
   "source": [
    "# Build dynamic save directory from author_input\n",
    "if \"author_input\" in globals():\n",
    "    author_name = author_input.value.strip()\n",
    "    # Normalize folder name: replace spaces, remove symbols\n",
    "    safe_author = re.sub(r\"[^A-Za-z0-9_-]\", \"_\", author_name)\n",
    "    save_dir = f\"./bot_{safe_author}\" if safe_author else \"./bot_model\"\n",
    "else:\n",
    "    save_dir = \"./bot_model\"\n",
    "\n",
    "print(f\"Guardando el modelo en: {save_dir}\")\n",
    "\n",
    "try:\n",
    "    trainer.train()\n",
    "finally:\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# Save model and tokenizer\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "\n",
    "print(f\"Modelo y tokenizer guardados en: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "R39Q3MBr6Z5E",
   "metadata": {
    "id": "R39Q3MBr6Z5E"
   },
   "source": [
    "## Comparador de respuestas entre modelos\n",
    "\n",
    "Esta celda carga el modelo base y el modelo fine-tuneado, y define un comparador para generar respuestas con ambos a partir de un mismo prompt. De esta forma se puede inspeccionar cualitativamente el efecto del fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681c893",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7681c893",
    "outputId": "25746386-54f0-42b5-ac98-132721df9585"
   },
   "outputs": [],
   "source": [
    "# Ensure save_dir exists (from training step)\n",
    "if \"save_dir\" not in globals():\n",
    "    save_dir = \"./bot_model\"  # fallback directory if not defined\n",
    "\n",
    "# Build author tag used during preprocessing and training\n",
    "if \"author_input\" in globals() and author_input.value.strip():\n",
    "    AUTHOR_TAG = f\"[{author_input.value.strip()}]\"\n",
    "else:\n",
    "    AUTHOR_TAG = \"[NICO]\"  # default fallback\n",
    "\n",
    "# Load base model with the same tokenizer (must match special tokens)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\"DeepESP/gpt2-spanish\")\n",
    "base_model.resize_token_embeddings(len(tokenizer))\n",
    "base_model.to(device)\n",
    "base_model.eval()\n",
    "\n",
    "# Load fine-tuned model\n",
    "fine_model = AutoModelForCausalLM.from_pretrained(save_dir).to(device)\n",
    "fine_model.eval()\n",
    "\n",
    "\n",
    "def generate_response(\n",
    "    prompt: str,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    max_new_tokens: int = 60\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Generate a response following the conversational format used during training.\n",
    "    The input prompt is plain text from the user (no tags).\n",
    "    The model should interpret it as a message from the other participant.\n",
    "    \"\"\"\n",
    "\n",
    "    # Construct formatted input according to training structure\n",
    "    formatted_prompt = (\n",
    "        f\"<|talk|><|ax1|> [OTRO] {prompt.strip()} <|ax2|> {AUTHOR_TAG} \"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=True,\n",
    "        temperature=0.8,\n",
    "        top_p=0.92,\n",
    "        repetition_penalty=1.9,\n",
    "        no_repeat_ngram_size=3,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "\n",
    "    # Truncate at end-of-text tag if present\n",
    "    if \"<|endoftext|>\" in generated:\n",
    "        generated = generated.split(\"<|endoftext|>\")[0]\n",
    "\n",
    "    # Keep only text after <|ax2|>\n",
    "    if \"<|ax2|>\" in generated:\n",
    "        generated = generated.split(\"<|ax2|>\", 1)[-1].strip()\n",
    "\n",
    "    # Remove role tags and internal separators from visible output\n",
    "    generated = generated.replace(AUTHOR_TAG, \"\")\n",
    "    generated = generated.replace(\"[OTRO]\", \"\")\n",
    "    generated = generated.replace(MSG_SEP, \" \")\n",
    "\n",
    "    # Final whitespace cleanup\n",
    "    response = re.sub(r\"\\s+\", \" \", generated).strip()\n",
    "    return response if response else \"(no generated response)\"\n",
    "\n",
    "\n",
    "def compare_models(prompt: str):\n",
    "    \"\"\"Generate and print responses from both models for comparison.\"\"\"\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    base_resp = generate_response(prompt, base_model, tokenizer)\n",
    "    fine_resp = generate_response(prompt, fine_model, tokenizer)\n",
    "\n",
    "    print(\"\\n----------------------------------\")\n",
    "    print(\"Base model:\\n\", base_resp)\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"Fine-tuned model:\\n\", fine_resp)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "\n",
    "# Extract prompts from validation set and sample a few\n",
    "val_prompts = [ex[\"prompt\"] for ex in datasets[\"validation\"]]\n",
    "sample_prompts = random.sample(val_prompts, min(5, len(val_prompts)))\n",
    "\n",
    "print(\"\\n=== Model comparison using validation samples ===\")\n",
    "for q in sample_prompts:\n",
    "    # Remove framework tags and internal separators\n",
    "    clean_q = (\n",
    "        q.replace(\"<|talk|>\", \"\")\n",
    "         .replace(\"<|ax1|>\", \"\")\n",
    "         .replace(\"<|ax2|>\", \"\")\n",
    "         .replace(\"<|endoftext|>\", \"\")\n",
    "         .replace(MSG_SEP, \" \")\n",
    "         .replace(AUTHOR_TAG, \"\")\n",
    "         .replace(\"[OTRO]\", \"\")\n",
    "         .strip()\n",
    "    )\n",
    "    compare_models(clean_q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_aqG3m2-7K7Y",
   "metadata": {
    "id": "_aqG3m2-7K7Y"
   },
   "source": [
    "## Chat interactivo\n",
    "\n",
    "Esta celda permite interactuar con el modelo fine-tuneado mediante entrada por consola. El usuario puede escribir mensajes y recibir respuestas del modelo. Para finalizar la sesión, ingresar salir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f21c85",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "39f21c85",
    "outputId": "dc6898b9-4ee1-4243-baf7-7e6cb4e00ae4"
   },
   "outputs": [],
   "source": [
    "def clean_user_input(text: str) -> str:\n",
    "    \"\"\"Remove training tags from user input to avoid formatting conflicts.\"\"\"\n",
    "    text = text.replace(\"<|talk|>\", \"\")\n",
    "    text = text.replace(\"<|ax1|>\", \"\")\n",
    "    text = text.replace(\"<|ax2|>\", \"\")\n",
    "    text = text.replace(\"<|endoftext|>\", \"\")\n",
    "    text = text.replace(MSG_SEP, \" \")\n",
    "    text = text.replace(AUTHOR_TAG, \"\")\n",
    "    text = text.replace(\"[OTRO]\", \"\")\n",
    "    return text.strip()\n",
    "\n",
    "print(\"=== Interactive chat with the fine-tuned model ===\")\n",
    "print(\"(Type 'salir' to exit)\\n\")\n",
    "\n",
    "while True:\n",
    "    user_msg = input(\"You: \").strip()\n",
    "\n",
    "    if user_msg.lower() == \"salir\":\n",
    "        print(\"Model: session finished.\")\n",
    "        break\n",
    "\n",
    "    # Remove unwanted tags and tokens\n",
    "    user_msg = clean_user_input(user_msg)\n",
    "\n",
    "    # Generate model response\n",
    "    response = generate_response(user_msg, fine_model, tokenizer)\n",
    "    print(f\"Model: {response}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qMcU7Rw77hYC",
   "metadata": {
    "id": "qMcU7Rw77hYC"
   },
   "source": [
    "## Evaluación cuantitativa y reporte final\n",
    "\n",
    "Esta celda evalúa cuantitativamente el modelo base y el modelo fine-tuneado sobre el conjunto de validación. Se calcula la pérdida media de cross-entropy y la perplexity aproximada, y se reporta la mejora relativa del modelo fine-tuneado. Finalmente, se muestra una comparación gráfica sencilla entre ambos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0044a4d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "0044a4d8",
    "outputId": "03401036-f937-40fb-c39e-e0988f8bfccd"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataset, max_batches: int = 200):\n",
    "    \"\"\"\n",
    "    Evaluate a causal language model on a subset of the dataset.\n",
    "\n",
    "    The function computes the average cross-entropy loss and derives\n",
    "    perplexity as exp(loss). It iterates over individual examples,\n",
    "    feeding input_ids as both inputs and labels.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, example in enumerate(tqdm(dataset, desc=\"Evaluando...\")):\n",
    "            if i >= max_batches:\n",
    "                break\n",
    "\n",
    "            input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0).to(device)\n",
    "            outputs = model(input_ids, labels=input_ids)\n",
    "            losses.append(outputs.loss.item())\n",
    "\n",
    "    avg_loss = sum(losses) / len(losses)\n",
    "    try:\n",
    "        perp = math.exp(avg_loss)\n",
    "    except OverflowError:\n",
    "        perp = float(\"inf\")\n",
    "\n",
    "    return {\"cross_entropy\": avg_loss, \"perplexity\": perp}\n",
    "\n",
    "\n",
    "# Evaluate base and fine-tuned models on the validation set\n",
    "metrics_base = evaluate_model(base_model, lm_datasets[\"validation\"])\n",
    "metrics_fine = evaluate_model(fine_model, lm_datasets[\"validation\"])\n",
    "\n",
    "print(\"\\nResultados de evaluación:\")\n",
    "print(\n",
    "    f\"Base model  → Cross-Entropy: {metrics_base['cross_entropy']:.3f} | \"\n",
    "    f\"Perplexity: {metrics_base['perplexity']:.2f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Fine-tuned  → Cross-Entropy: {metrics_fine['cross_entropy']:.3f} | \"\n",
    "    f\"Perplexity: {metrics_fine['perplexity']:.2f}\"\n",
    ")\n",
    "\n",
    "# Relative improvement in perplexity (percentage)\n",
    "improvement = (\n",
    "    (metrics_base[\"perplexity\"] - metrics_fine[\"perplexity\"])\n",
    "    / metrics_base[\"perplexity\"]\n",
    "    * 100\n",
    ")\n",
    "\n",
    "print(f\"Mejora relativa en perplexity: {improvement:.2f}%\")\n",
    "\n",
    "# Simple barplot comparison\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    x=[\"Base\", \"Fine-tune\"],\n",
    "    y=[metrics_base[\"perplexity\"], metrics_fine[\"perplexity\"]],\n",
    ")\n",
    "plt.title(\"Comparación de perplexity entre modelos\")\n",
    "plt.ylabel(\"Perplexity (menor es mejor)\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851204f8-6882-4a3e-8fb3-b4cfc4b23225",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "000077e3c223477cb0974127a96bc659": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FileUploadModel",
     "state": {
      "_counter": 1,
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FileUploadModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "FileUploadView",
      "accept": ".txt",
      "button_style": "",
      "data": [
       null
      ],
      "description": "Subir chat (.txt)",
      "description_tooltip": null,
      "disabled": false,
      "error": "",
      "icon": "upload",
      "layout": "IPY_MODEL_d048b13325434cdf828d5734027ee94e",
      "metadata": [
       {
        "lastModified": 1762789400422,
        "name": "chat.txt",
        "size": 5746144,
        "type": "text/plain"
       }
      ],
      "multiple": false,
      "style": "IPY_MODEL_5d736683a7da43d8a0fcf6d2e568d042"
     }
    },
    "007644d9a9654065803eb013474685b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0523b6f5933b4dd5922766a1fcba0d78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "081eac8ac59942d78338412589a88bc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0523b6f5933b4dd5922766a1fcba0d78",
      "placeholder": "​",
      "style": "IPY_MODEL_c6435a321a1e4875bf63952447887b77",
      "value": "Batches: 100%"
     }
    },
    "0b0fbe7a20ca465b872fd12ba3e8a043": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d9b7e0264f04847847001bd062e75dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1244f08ba56846b392169c6b39d4ecc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "14b03e931fdf4a408ff52fb0286bd58f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1514ad0ca9424e6e8cc2bbea339c6bf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "166cae34ef4742e68ee37d6d9b55204d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1b89890b423249ddb03219ed985d6b62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6afbafbc97a54acf9d380ae1249ca133",
       "IPY_MODEL_000077e3c223477cb0974127a96bc659",
       "IPY_MODEL_5a2fc8da6b934c85b941a5176456de43",
       "IPY_MODEL_281c39c324384aa097590eac129a3aca",
       "IPY_MODEL_1f588ccdb55e4858b356af6ba71c66b1",
       "IPY_MODEL_c09e9e96550040789e4ee73f72a62412",
       "IPY_MODEL_640f532bdc0d4fa598222c82e9cc034c"
      ],
      "layout": "IPY_MODEL_716f457b8c774135a48d0b66b9f2240a"
     }
    },
    "1ee3cdcc9c5f44aca8102fcac055fa7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f588ccdb55e4858b356af6ba71c66b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": false,
      "description": "time_gap (h):",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_8d73ef5112a346a6ac9edfe7b91b8b1c",
      "max": 24,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_386f1dc567e0401c89e32f2d2191ab35",
      "value": 3
     }
    },
    "22f9603a839a47e3a9189db8e15c321c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "23c66bbba40e433f9487149dde5ef7ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b31b99f3917e4c59861357632713da86",
      "placeholder": "​",
      "style": "IPY_MODEL_1244f08ba56846b392169c6b39d4ecc9",
      "value": " 14831/14831 [00:04&lt;00:00, 3085.26 examples/s]"
     }
    },
    "281c39c324384aa097590eac129a3aca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntSliderModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntSliderModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "IntSliderView",
      "continuous_update": false,
      "description": "k_history:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_64a1f1d0ac8c4a22bb0ecbd53b6fa308",
      "max": 10,
      "min": 1,
      "orientation": "horizontal",
      "readout": true,
      "readout_format": "d",
      "step": 1,
      "style": "IPY_MODEL_606382c47400446686a6ac8faca34364",
      "value": 4
     }
    },
    "37066bd6b5dd4a96adf4dde0f00d0249": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "60%"
     }
    },
    "386f1dc567e0401c89e32f2d2191ab35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "38a1ffb2e99047f18f80780e21da2e09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3df323df78aa4b92a202dadfc96ce075": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4440cab6284145629c7bb21906b0dd08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_731ab9c47cad4cb0b2376f97f270d3c7",
      "max": 14831,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_166cae34ef4742e68ee37d6d9b55204d",
      "value": 14831
     }
    },
    "44de7c02ff9f4db78d3a83392220e4b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ccc4bb50c9d4a93a95f3db1cdc4363c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_eaf0a883b0c24044ad7444452a57a5df",
       "IPY_MODEL_5baf19d9a1c34043aa6a7b9bac84aa24",
       "IPY_MODEL_d1086cde5e554ce48cdad8a7994cec43"
      ],
      "layout": "IPY_MODEL_50a3c9e3797b4f529f107aa67bd59797"
     }
    },
    "4d78106f1c194d55983b58c1e44383b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44de7c02ff9f4db78d3a83392220e4b1",
      "max": 671,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f39d1805738418b929132e9d57d66b3",
      "value": 671
     }
    },
    "50a3c9e3797b4f529f107aa67bd59797": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54b5173fa8674eb9b1102bf9d459cad8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "55a5d08862dd446595c68ed061dcd860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5a2fc8da6b934c85b941a5176456de43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "TextModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "TextModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "TextView",
      "continuous_update": true,
      "description": "Autor:",
      "description_tooltip": null,
      "disabled": false,
      "layout": "IPY_MODEL_37066bd6b5dd4a96adf4dde0f00d0249",
      "placeholder": "Nombre exactamente como figura en el chat",
      "style": "IPY_MODEL_54b5173fa8674eb9b1102bf9d459cad8",
      "value": "Nico Bazan"
     }
    },
    "5baf19d9a1c34043aa6a7b9bac84aa24": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de0fb81662ce40e58b8dd095e5e041eb",
      "max": 3708,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4297894b3bd43c4af3bdbcd491ea44f",
      "value": 3708
     }
    },
    "5d736683a7da43d8a0fcf6d2e568d042": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "button_color": null,
      "font_weight": ""
     }
    },
    "5dedbcbc4bdc458bb17dcac1063ed017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5ff427dd866d407a871c2ee09717fb71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_081eac8ac59942d78338412589a88bc5",
       "IPY_MODEL_b740b650766d4f37a726e446d315f6df",
       "IPY_MODEL_f0918d6914844df8be487183b2406baa"
      ],
      "layout": "IPY_MODEL_97c87949d2bd49e88ccfa1f4dd9326cf"
     }
    },
    "606382c47400446686a6ac8faca34364": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "SliderStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "SliderStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": "",
      "handle_color": null
     }
    },
    "63405775b29449c389d6e68f1baa7d58": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "640f532bdc0d4fa598222c82e9cc034c": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_95141b2d7da843b6bb6c63a2021acf7b",
      "msg_id": "",
      "outputs": [
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Procesando chat (k-turns con roles)...\n"
        ]
       },
       {
        "name": "stdout",
        "output_type": "stream",
        "text": [
         "Total de turnos agrupados: 47431\n",
         "Total de pares generados: 22672\n",
         "Pares generados: 22672\n",
         "\n",
         "Ejemplo de PROMPT:\n",
         "<|talk|><|ax1|> [OTRO] de vuelta mil gracias por traerme <|ax2|>\n",
         "\n",
         "Ejemplo de RESPONSE:\n",
         " de nada lolaa <|msg_sep|> no tengas vergüenza, no queremos q te vuelvas sola <|msg_sep|> ta peligroso <|msg_sep|> no nos cuesta nada, ni ami ni a juan <|msg_sep|> posta <|endoftext|>\n",
         "\n",
         "Variables disponibles para las siguientes celdas: 'prompts', 'responses'.\n"
        ]
       }
      ]
     }
    },
    "64a1f1d0ac8c4a22bb0ecbd53b6fa308": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6afbafbc97a54acf9d380ae1249ca133": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63405775b29449c389d6e68f1baa7d58",
      "placeholder": "​",
      "style": "IPY_MODEL_22f9603a839a47e3a9189db8e15c321c",
      "value": "<b>Procesamiento interactivo del chat de WhatsApp</b>"
     }
    },
    "6f39d1805738418b929132e9d57d66b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6fcadb3d803a4242867e482192a54a8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3385ca7ad084b76b54bd792c5c12ecc",
      "placeholder": "​",
      "style": "IPY_MODEL_b37c77039daa4165ace0be1507c4124c",
      "value": "Generating train split: "
     }
    },
    "7089428aff0b4bafb56fde74ecd2c3e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "716f457b8c774135a48d0b66b9f2240a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7261dd8dcb8642a5af09d438949f92eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6fcadb3d803a4242867e482192a54a8d",
       "IPY_MODEL_f34d3b82ee69493d875fb0e6e5c4e279",
       "IPY_MODEL_974cdc2c42ed478eb7fe57b297ea5d8d"
      ],
      "layout": "IPY_MODEL_1ee3cdcc9c5f44aca8102fcac055fa7b"
     }
    },
    "731ab9c47cad4cb0b2376f97f270d3c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "757b8d1a630d472ebded8cc6d0ae2c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7afa75f5ab2c4797b3bf7040d420a9f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee5a23335ed2409896ba872cf65a8de2",
      "placeholder": "​",
      "style": "IPY_MODEL_0d9b7e0264f04847847001bd062e75dc",
      "value": "Map: 100%"
     }
    },
    "8d73ef5112a346a6ac9edfe7b91b8b1c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95141b2d7da843b6bb6c63a2021acf7b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "974cdc2c42ed478eb7fe57b297ea5d8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_757b8d1a630d472ebded8cc6d0ae2c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_38a1ffb2e99047f18f80780e21da2e09",
      "value": " 18539/0 [00:00&lt;00:00, 78506.35 examples/s]"
     }
    },
    "97c87949d2bd49e88ccfa1f4dd9326cf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7d44eeadec440b885db0b3266aff313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7afa75f5ab2c4797b3bf7040d420a9f1",
       "IPY_MODEL_4440cab6284145629c7bb21906b0dd08",
       "IPY_MODEL_23c66bbba40e433f9487149dde5ef7ad"
      ],
      "layout": "IPY_MODEL_c621cce4af43498c86a9db93fa37d9d2"
     }
    },
    "a8111075fbd045b7a04864291fb79ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b31b99f3917e4c59861357632713da86": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b37c77039daa4165ace0be1507c4124c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3880be52dd04da1830ba8537b92efe7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b3cd5c2b87d745d489eaa52d8d9e354e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14b03e931fdf4a408ff52fb0286bd58f",
      "placeholder": "​",
      "style": "IPY_MODEL_d91cc7a0aaf743b4aeff8be2958d7464",
      "value": " 671/671 [00:17&lt;00:00, 67.85it/s]"
     }
    },
    "b740b650766d4f37a726e446d315f6df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3df323df78aa4b92a202dadfc96ce075",
      "max": 671,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55a5d08862dd446595c68ed061dcd860",
      "value": 671
     }
    },
    "c09e9e96550040789e4ee73f72a62412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ButtonModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ButtonModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ButtonView",
      "button_style": "primary",
      "description": "Procesar chat",
      "disabled": false,
      "icon": "",
      "layout": "IPY_MODEL_e2f56bcb29b046fc88286e440da594cb",
      "style": "IPY_MODEL_1514ad0ca9424e6e8cc2bbea339c6bf6",
      "tooltip": ""
     }
    },
    "c3f3f23759714a02b0c4a11ffcef09d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f306d239ed9047ddbae48e830ff0e6c7",
       "IPY_MODEL_4d78106f1c194d55983b58c1e44383b5",
       "IPY_MODEL_b3cd5c2b87d745d489eaa52d8d9e354e"
      ],
      "layout": "IPY_MODEL_d71a7989630f41c6811674058b2a1a5b"
     }
    },
    "c621cce4af43498c86a9db93fa37d9d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6435a321a1e4875bf63952447887b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6b5b1bb6987432fa77a40789433950e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d048b13325434cdf828d5734027ee94e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d1086cde5e554ce48cdad8a7994cec43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c6b5b1bb6987432fa77a40789433950e",
      "placeholder": "​",
      "style": "IPY_MODEL_007644d9a9654065803eb013474685b7",
      "value": " 3708/3708 [00:01&lt;00:00, 3138.19 examples/s]"
     }
    },
    "d4297894b3bd43c4af3bdbcd491ea44f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d71a7989630f41c6811674058b2a1a5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d91cc7a0aaf743b4aeff8be2958d7464": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de0fb81662ce40e58b8dd095e5e041eb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e254882eeb8443658a6f037d654f0032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f56bcb29b046fc88286e440da594cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eabf5e94e97a4cd5aeb7993498bdb3b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eaf0a883b0c24044ad7444452a57a5df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7089428aff0b4bafb56fde74ecd2c3e5",
      "placeholder": "​",
      "style": "IPY_MODEL_eabf5e94e97a4cd5aeb7993498bdb3b2",
      "value": "Map: 100%"
     }
    },
    "eda887369c4d450f855ebecc8bfb3f4b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "ee5a23335ed2409896ba872cf65a8de2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0918d6914844df8be487183b2406baa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e254882eeb8443658a6f037d654f0032",
      "placeholder": "​",
      "style": "IPY_MODEL_5dedbcbc4bdc458bb17dcac1063ed017",
      "value": " 671/671 [00:39&lt;00:00, 44.15it/s]"
     }
    },
    "f306d239ed9047ddbae48e830ff0e6c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b0fbe7a20ca465b872fd12ba3e8a043",
      "placeholder": "​",
      "style": "IPY_MODEL_b3880be52dd04da1830ba8537b92efe7",
      "value": "Batches: 100%"
     }
    },
    "f3385ca7ad084b76b54bd792c5c12ecc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f34d3b82ee69493d875fb0e6e5c4e279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eda887369c4d450f855ebecc8bfb3f4b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8111075fbd045b7a04864291fb79ef3",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
